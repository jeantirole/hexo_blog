<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title> </title><meta property="og:type" content="blog"><meta property="og:title" content=""><meta property="og:url" content="http://yoursite.com/"><meta property="og:site_name" content=""><meta property="og:locale" content="en_US"><meta property="og:image" content="http://yoursite.com/img/og_image.png"><meta property="article:author" content="Eric Park"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://yoursite.com"},"headline":"","image":["http://yoursite.com/img/og_image.png"],"author":{"@type":"Person","name":"Eric Park"},"description":""}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><meta name="generator" content="Hexo 5.1.1"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item is-active" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-12-tablet is-12-desktop is-12-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2020-09-22T00:05:12.000Z" title="2020-09-22T00:05:12.000Z">2020-09-22</time></span><span class="level-item">Updated&nbsp;<time dateTime="2020-09-22T05:53:33.290Z" title="2020-09-22T05:53:33.290Z">2020-09-22</time></span><span class="level-item"><a class="link-muted" href="/categories/Kaggle/">Kaggle</a></span><span class="level-item">15 minutes read (About 2214 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/09/22/project_kaggle_m5_0922%20Modeling/">Kaggle M5 Competition Part 2 -Modeling</a></h1><div class="content"><blockquote>
<p>Contents of table:</p>
<ul>
<li><a href="#kaggle-m5-competition-part-2--modeling">Kaggle M5 Competition Part 2 -Modeling</a></li>
<li><a href="#5-feature-engineering">5. Feature Engineering </a></li>
<li><a href="#6-modeling-and-prediction">6. Modeling and Prediction</a></li>
</ul>
</blockquote>
<hr>
<hr>
<h1 id="Kaggle-M5-Competition-Part-2-Modeling"><a href="#Kaggle-M5-Competition-Part-2-Modeling" class="headerlink" title="Kaggle M5 Competition Part 2 -Modeling"></a>Kaggle M5 Competition Part 2 -Modeling</h1><hr>
<h1 id="5-Feature-Engineering"><a href="#5-Feature-Engineering" class="headerlink" title="5. Feature Engineering"></a>5. Feature Engineering</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#5.1 Label Encoding </span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#id, department, category, store, state 를 코드값으로 저장 </span></span><br><span class="line">d_id = dict(zip(df.id.cat.codes, df.id))</span><br><span class="line">d_item_id = dict(zip(df.item_id.cat.codes, df.item_id))</span><br><span class="line">d_dept_id = dict(zip(df.dept_id.cat.codes, df.dept_id))</span><br><span class="line">d_cat_id = dict(zip(df.cat_id.cat.codes, df.cat_id))</span><br><span class="line">d_store_id = dict(zip(df.store_id.cat.codes, df.store_id))</span><br><span class="line">d_state_id = dict(zip(df.state_id.cat.codes, df.state_id))</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#1</span></span><br><span class="line">gc.collect()</span><br><span class="line"></span><br><span class="line"><span class="comment">#2</span></span><br><span class="line">df.d = df[<span class="string">&#x27;d&#x27;</span>].apply(<span class="keyword">lambda</span> x: x.split(<span class="string">&#x27;_&#x27;</span>)[<span class="number">1</span>]).astype(np.int16)</span><br><span class="line">cols = df.dtypes.index.tolist()</span><br><span class="line">types = df.dtypes.values.tolist()</span><br><span class="line"><span class="keyword">for</span> i,type <span class="keyword">in</span> enumerate(types):</span><br><span class="line">    <span class="keyword">if</span> type.name == <span class="string">&#x27;category&#x27;</span>:</span><br><span class="line">        df[cols[i]] = df[cols[i]].cat.codes</span><br><span class="line">        </span><br><span class="line"><span class="comment">#3</span></span><br><span class="line">df.drop(<span class="string">&#x27;date&#x27;</span>,axis=<span class="number">1</span>,inplace=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#5.2 introduce lags</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#lag col들을 추가</span></span><br><span class="line">lags = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">6</span>,<span class="number">12</span>,<span class="number">24</span>,<span class="number">36</span>]</span><br><span class="line"><span class="keyword">for</span> lag <span class="keyword">in</span> lags:</span><br><span class="line">    df[<span class="string">&#x27;sold_lag_&#x27;</span>+str(lag)] = df.groupby([<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;item_id&#x27;</span>, <span class="string">&#x27;dept_id&#x27;</span>, <span class="string">&#x27;cat_id&#x27;</span>, <span class="string">&#x27;store_id&#x27;</span>, <span class="string">&#x27;state_id&#x27;</span>],as_index=<span class="literal">False</span>)[<span class="string">&#x27;sold&#x27;</span>].shift(lag).astype(np.float16)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#5.3 Mean Encoding </span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">%time</span><br><span class="line"><span class="comment">#판매량 평균을 wrt item, state, store, category, department 별로 col 생성 </span></span><br><span class="line">df[<span class="string">&#x27;iteam_sold_avg&#x27;</span>] = df.groupby(<span class="string">&#x27;item_id&#x27;</span>)[<span class="string">&#x27;sold&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).astype(np.float16)</span><br><span class="line">df[<span class="string">&#x27;state_sold_avg&#x27;</span>] = df.groupby(<span class="string">&#x27;state_id&#x27;</span>)[<span class="string">&#x27;sold&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).astype(np.float16)</span><br><span class="line">df[<span class="string">&#x27;store_sold_avg&#x27;</span>] = df.groupby(<span class="string">&#x27;store_id&#x27;</span>)[<span class="string">&#x27;sold&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).astype(np.float16)</span><br><span class="line">df[<span class="string">&#x27;cat_sold_avg&#x27;</span>] = df.groupby(<span class="string">&#x27;cat_id&#x27;</span>)[<span class="string">&#x27;sold&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).astype(np.float16)</span><br><span class="line">df[<span class="string">&#x27;dept_sold_avg&#x27;</span>] = df.groupby(<span class="string">&#x27;dept_id&#x27;</span>)[<span class="string">&#x27;sold&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).astype(np.float16)</span><br><span class="line">df[<span class="string">&#x27;cat_dept_sold_avg&#x27;</span>] = df.groupby([<span class="string">&#x27;cat_id&#x27;</span>,<span class="string">&#x27;dept_id&#x27;</span>])[<span class="string">&#x27;sold&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).astype(np.float16)</span><br><span class="line">df[<span class="string">&#x27;store_item_sold_avg&#x27;</span>] = df.groupby([<span class="string">&#x27;store_id&#x27;</span>,<span class="string">&#x27;item_id&#x27;</span>])[<span class="string">&#x27;sold&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).astype(np.float16)</span><br><span class="line">df[<span class="string">&#x27;cat_item_sold_avg&#x27;</span>] = df.groupby([<span class="string">&#x27;cat_id&#x27;</span>,<span class="string">&#x27;item_id&#x27;</span>])[<span class="string">&#x27;sold&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).astype(np.float16)</span><br><span class="line">df[<span class="string">&#x27;dept_item_sold_avg&#x27;</span>] = df.groupby([<span class="string">&#x27;dept_id&#x27;</span>,<span class="string">&#x27;item_id&#x27;</span>])[<span class="string">&#x27;sold&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).astype(np.float16)</span><br><span class="line">df[<span class="string">&#x27;state_store_sold_avg&#x27;</span>] = df.groupby([<span class="string">&#x27;state_id&#x27;</span>,<span class="string">&#x27;store_id&#x27;</span>])[<span class="string">&#x27;sold&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).astype(np.float16)</span><br><span class="line">df[<span class="string">&#x27;state_store_cat_sold_avg&#x27;</span>] = df.groupby([<span class="string">&#x27;state_id&#x27;</span>,<span class="string">&#x27;store_id&#x27;</span>,<span class="string">&#x27;cat_id&#x27;</span>])[<span class="string">&#x27;sold&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).astype(np.float16)</span><br><span class="line">df[<span class="string">&#x27;store_cat_dept_sold_avg&#x27;</span>] = df.groupby([<span class="string">&#x27;store_id&#x27;</span>,<span class="string">&#x27;cat_id&#x27;</span>,<span class="string">&#x27;dept_id&#x27;</span>])[<span class="string">&#x27;sold&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).astype(np.float16)</span><br></pre></td></tr></table></figure>

<pre><code>Wall time: 1 ms</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#5.4 Rolling Window Statistics </span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">&#x27;rolling_sold_mean&#x27;</span>] = df.groupby([<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;item_id&#x27;</span>, <span class="string">&#x27;dept_id&#x27;</span>, <span class="string">&#x27;cat_id&#x27;</span>, <span class="string">&#x27;store_id&#x27;</span>, <span class="string">&#x27;state_id&#x27;</span>])[<span class="string">&#x27;sold&#x27;</span>].transform(<span class="keyword">lambda</span> x: x.rolling(window=<span class="number">7</span>).mean()).astype(np.float16)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#5.5 Expanding Window Statistics  </span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">&#x27;expanding_sold_mean&#x27;</span>] = df.groupby([<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;item_id&#x27;</span>, <span class="string">&#x27;dept_id&#x27;</span>, <span class="string">&#x27;cat_id&#x27;</span>, <span class="string">&#x27;store_id&#x27;</span>, <span class="string">&#x27;state_id&#x27;</span>])[<span class="string">&#x27;sold&#x27;</span>].transform(<span class="keyword">lambda</span> x: x.expanding(<span class="number">2</span>).mean()).astype(np.float16)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#5.6 Trends</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Selling Trend는 간단하게, 평균보다 큰지 작은지 만을 비교. </span></span><br><span class="line">df[<span class="string">&#x27;daily_avg_sold&#x27;</span>] = df.groupby([<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;item_id&#x27;</span>, <span class="string">&#x27;dept_id&#x27;</span>, <span class="string">&#x27;cat_id&#x27;</span>, <span class="string">&#x27;store_id&#x27;</span>, <span class="string">&#x27;state_id&#x27;</span>,<span class="string">&#x27;d&#x27;</span>])[<span class="string">&#x27;sold&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).astype(np.float16)</span><br><span class="line">df[<span class="string">&#x27;avg_sold&#x27;</span>] = df.groupby([<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;item_id&#x27;</span>, <span class="string">&#x27;dept_id&#x27;</span>, <span class="string">&#x27;cat_id&#x27;</span>, <span class="string">&#x27;store_id&#x27;</span>, <span class="string">&#x27;state_id&#x27;</span>])[<span class="string">&#x27;sold&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).astype(np.float16)</span><br><span class="line">df[<span class="string">&#x27;selling_trend&#x27;</span>] = (df[<span class="string">&#x27;daily_avg_sold&#x27;</span>] - df[<span class="string">&#x27;avg_sold&#x27;</span>]).astype(np.float16)</span><br><span class="line">df.drop([<span class="string">&#x27;daily_avg_sold&#x27;</span>,<span class="string">&#x27;avg_sold&#x27;</span>],axis=<span class="number">1</span>,inplace=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#5.7 Save the data </span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#lag 추가로 인해서, d 35까지 빈 row 들이 많이 발생했으므로 해당기간을 제외. </span></span><br><span class="line">df = df[df[<span class="string">&#x27;d&#x27;</span>]&gt;=<span class="number">36</span>]</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.info()</span><br></pre></td></tr></table></figure>

<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
Int64Index: 58967660 entries, 1067150 to 60034809
Data columns (total 43 columns):
id                          int16
item_id                     int16
dept_id                     int8
cat_id                      int8
store_id                    int8
state_id                    int8
d                           int16
sold                        int16
wm_yr_wk                    int16
weekday                     int8
wday                        int8
month                       int8
year                        int16
event_name_1                int8
event_type_1                int8
event_name_2                int8
event_type_2                int8
snap_CA                     int8
snap_TX                     int8
snap_WI                     int8
sell_price                  float16
sold_lag_1                  float16
sold_lag_2                  float16
sold_lag_3                  float16
sold_lag_6                  float16
sold_lag_12                 float16
sold_lag_24                 float16
sold_lag_36                 float16
iteam_sold_avg              float16
state_sold_avg              float16
store_sold_avg              float16
cat_sold_avg                float16
dept_sold_avg               float16
cat_dept_sold_avg           float16
store_item_sold_avg         float16
cat_item_sold_avg           float16
dept_item_sold_avg          float16
state_store_sold_avg        float16
state_store_cat_sold_avg    float16
store_cat_dept_sold_avg     float16
rolling_sold_mean           float16
expanding_sold_mean         float16
selling_trend               float16
dtypes: float16(23), int16(6), int8(14)
memory usage: 4.4 GB</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df.to_pickle(<span class="string">&#x27;data.pkl&#x27;</span>)</span><br><span class="line"><span class="keyword">del</span> df</span><br><span class="line">gc.collect()</span><br></pre></td></tr></table></figure>



<h1 id="6-Modeling-and-Prediction"><a href="#6-Modeling-and-Prediction" class="headerlink" title="6. Modeling and Prediction"></a>6. Modeling and Prediction</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">%time </span><br><span class="line">data = pd.read_pickle(<span class="string">&#x27;data.pkl&#x27;</span>) <span class="comment"># FE후에 pickle 형태로 저장시켰던 데이터를 로드. </span></span><br><span class="line">valid = data[(data[<span class="string">&#x27;d&#x27;</span>]&gt;=<span class="number">1914</span>) &amp; (data[<span class="string">&#x27;d&#x27;</span>]&lt;<span class="number">1942</span>)][[<span class="string">&#x27;id&#x27;</span>,<span class="string">&#x27;d&#x27;</span>,<span class="string">&#x27;sold&#x27;</span>]] <span class="comment"># 1914 ~ 1942 validation period</span></span><br><span class="line">test = data[data[<span class="string">&#x27;d&#x27;</span>]&gt;=<span class="number">1942</span>][[<span class="string">&#x27;id&#x27;</span>,<span class="string">&#x27;d&#x27;</span>,<span class="string">&#x27;sold&#x27;</span>]] <span class="comment"># d &gt;= 1942 test and eval period </span></span><br><span class="line">eval_preds = test[<span class="string">&#x27;sold&#x27;</span>] <span class="comment"># eval = test</span></span><br><span class="line">valid_preds = valid[<span class="string">&#x27;sold&#x27;</span>] <span class="comment"># val = val </span></span><br></pre></td></tr></table></figure>

<pre><code>Wall time: 0 ns</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Get the store ids</span></span><br><span class="line">stores = sales.store_id.cat.codes.unique().tolist()</span><br><span class="line"><span class="keyword">for</span> store <span class="keyword">in</span> stores: <span class="comment">#store 별로 나눠서 prediction 진행 </span></span><br><span class="line">    df = data[data[<span class="string">&#x27;store_id&#x27;</span>]==store]</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#Split the data</span></span><br><span class="line">    X_train, y_train = df[df[<span class="string">&#x27;d&#x27;</span>]&lt;<span class="number">1914</span>].drop(<span class="string">&#x27;sold&#x27;</span>,axis=<span class="number">1</span>), df[df[<span class="string">&#x27;d&#x27;</span>]&lt;<span class="number">1914</span>][<span class="string">&#x27;sold&#x27;</span>]</span><br><span class="line">    X_valid, y_valid = df[(df[<span class="string">&#x27;d&#x27;</span>]&gt;=<span class="number">1914</span>) &amp; (df[<span class="string">&#x27;d&#x27;</span>]&lt;<span class="number">1942</span>)].drop(<span class="string">&#x27;sold&#x27;</span>,axis=<span class="number">1</span>), df[(df[<span class="string">&#x27;d&#x27;</span>]&gt;=<span class="number">1914</span>) &amp; (df[<span class="string">&#x27;d&#x27;</span>]&lt;<span class="number">1942</span>)][<span class="string">&#x27;sold&#x27;</span>]</span><br><span class="line">    X_test = df[df[<span class="string">&#x27;d&#x27;</span>]&gt;=<span class="number">1942</span>].drop(<span class="string">&#x27;sold&#x27;</span>,axis=<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#Train and validate</span></span><br><span class="line">    model = LGBMRegressor(</span><br><span class="line">        n_estimators=<span class="number">1000</span>,</span><br><span class="line">        learning_rate=<span class="number">0.3</span>,</span><br><span class="line">        subsample=<span class="number">0.8</span>,</span><br><span class="line">        colsample_bytree=<span class="number">0.8</span>,</span><br><span class="line">        max_depth=<span class="number">8</span>,</span><br><span class="line">        num_leaves=<span class="number">50</span>,</span><br><span class="line">        min_child_weight=<span class="number">300</span></span><br><span class="line">    )</span><br><span class="line">    print(<span class="string">&#x27;*****Prediction for Store: &#123;&#125;*****&#x27;</span>.format(d_store_id[store]))</span><br><span class="line">    model.fit(X_train, y_train, eval_set=[(X_train,y_train),(X_valid,y_valid)],</span><br><span class="line">             eval_metric=<span class="string">&#x27;rmse&#x27;</span>, verbose=<span class="number">20</span>, early_stopping_rounds=<span class="number">20</span>)</span><br><span class="line">             </span><br><span class="line">    valid_preds[X_valid.index] = model.predict(X_valid)</span><br><span class="line">    eval_preds[X_test.index] = model.predict(X_test)</span><br><span class="line">    filename = <span class="string">&#x27;model&#x27;</span>+str(d_store_id[store])+<span class="string">&#x27;.pkl&#x27;</span></span><br><span class="line">    <span class="comment"># save model</span></span><br><span class="line">    joblib.dump(model, filename)</span><br><span class="line">    <span class="keyword">del</span> model, X_train, y_train, X_valid, y_valid</span><br><span class="line">    gc.collect()</span><br></pre></td></tr></table></figure>

<pre><code>*****Prediction for Store: CA_1*****
Training until validation scores don&#39;t improve for 20 rounds
[20]    training&#39;s rmse: 0.843923    training&#39;s l2: 0.712206    valid_1&#39;s rmse: 0.556612    valid_1&#39;s l2: 0.309817
[40]    training&#39;s rmse: 0.805702    training&#39;s l2: 0.649156    valid_1&#39;s rmse: 0.536648    valid_1&#39;s l2: 0.287992
[60]    training&#39;s rmse: 0.782521    training&#39;s l2: 0.612339    valid_1&#39;s rmse: 0.529075    valid_1&#39;s l2: 0.27992
[80]    training&#39;s rmse: 0.765509    training&#39;s l2: 0.586004    valid_1&#39;s rmse: 0.519001    valid_1&#39;s l2: 0.269362
[100]    training&#39;s rmse: 0.746824    training&#39;s l2: 0.557746    valid_1&#39;s rmse: 0.516391    valid_1&#39;s l2: 0.26666
[120]    training&#39;s rmse: 0.736669    training&#39;s l2: 0.542682    valid_1&#39;s rmse: 0.512239    valid_1&#39;s l2: 0.262389
[140]    training&#39;s rmse: 0.725183    training&#39;s l2: 0.52589    valid_1&#39;s rmse: 0.507517    valid_1&#39;s l2: 0.257574
[160]    training&#39;s rmse: 0.71879    training&#39;s l2: 0.516659    valid_1&#39;s rmse: 0.503054    valid_1&#39;s l2: 0.253063
[180]    training&#39;s rmse: 0.713246    training&#39;s l2: 0.508719    valid_1&#39;s rmse: 0.501668    valid_1&#39;s l2: 0.25167
Early stopping, best iteration is:
[177]    training&#39;s rmse: 0.713815    training&#39;s l2: 0.509531    valid_1&#39;s rmse: 0.501194    valid_1&#39;s l2: 0.251195
*****Prediction for Store: CA_2*****
Training until validation scores don&#39;t improve for 20 rounds
[20]    training&#39;s rmse: 0.509193    training&#39;s l2: 0.259277    valid_1&#39;s rmse: 0.488679    valid_1&#39;s l2: 0.238808
[40]    training&#39;s rmse: 0.476985    training&#39;s l2: 0.227515    valid_1&#39;s rmse: 0.481392    valid_1&#39;s l2: 0.231738
[60]    training&#39;s rmse: 0.459124    training&#39;s l2: 0.210795    valid_1&#39;s rmse: 0.469844    valid_1&#39;s l2: 0.220753
[80]    training&#39;s rmse: 0.446454    training&#39;s l2: 0.199321    valid_1&#39;s rmse: 0.466131    valid_1&#39;s l2: 0.217278
[100]    training&#39;s rmse: 0.44062    training&#39;s l2: 0.194146    valid_1&#39;s rmse: 0.465138    valid_1&#39;s l2: 0.216353
[120]    training&#39;s rmse: 0.435579    training&#39;s l2: 0.189729    valid_1&#39;s rmse: 0.462275    valid_1&#39;s l2: 0.213698
[140]    training&#39;s rmse: 0.433312    training&#39;s l2: 0.187759    valid_1&#39;s rmse: 0.46174    valid_1&#39;s l2: 0.213204
[160]    training&#39;s rmse: 0.430487    training&#39;s l2: 0.185319    valid_1&#39;s rmse: 0.461825    valid_1&#39;s l2: 0.213283
Early stopping, best iteration is:
[149]    training&#39;s rmse: 0.431706    training&#39;s l2: 0.18637    valid_1&#39;s rmse: 0.461223    valid_1&#39;s l2: 0.212727
*****Prediction for Store: CA_3*****
Training until validation scores don&#39;t improve for 20 rounds
[20]    training&#39;s rmse: 1.31768    training&#39;s l2: 1.73629    valid_1&#39;s rmse: 0.620532    valid_1&#39;s l2: 0.38506
[40]    training&#39;s rmse: 1.25016    training&#39;s l2: 1.56289    valid_1&#39;s rmse: 0.599518    valid_1&#39;s l2: 0.359422
[60]    training&#39;s rmse: 1.21357    training&#39;s l2: 1.47275    valid_1&#39;s rmse: 0.583401    valid_1&#39;s l2: 0.340357
[80]    training&#39;s rmse: 1.18962    training&#39;s l2: 1.41519    valid_1&#39;s rmse: 0.580415    valid_1&#39;s l2: 0.336882
[100]    training&#39;s rmse: 1.16704    training&#39;s l2: 1.36198    valid_1&#39;s rmse: 0.573824    valid_1&#39;s l2: 0.329274
Early stopping, best iteration is:
[83]    training&#39;s rmse: 1.18341    training&#39;s l2: 1.40046    valid_1&#39;s rmse: 0.571149    valid_1&#39;s l2: 0.326211
*****Prediction for Store: CA_4*****
Training until validation scores don&#39;t improve for 20 rounds
[20]    training&#39;s rmse: 0.379545    training&#39;s l2: 0.144055    valid_1&#39;s rmse: 0.306421    valid_1&#39;s l2: 0.0938936
[40]    training&#39;s rmse: 0.362723    training&#39;s l2: 0.131568    valid_1&#39;s rmse: 0.296737    valid_1&#39;s l2: 0.0880528
[60]    training&#39;s rmse: 0.352526    training&#39;s l2: 0.124275    valid_1&#39;s rmse: 0.286469    valid_1&#39;s l2: 0.0820644
[80]    training&#39;s rmse: 0.347152    training&#39;s l2: 0.120515    valid_1&#39;s rmse: 0.283419    valid_1&#39;s l2: 0.0803261
[100]    training&#39;s rmse: 0.342128    training&#39;s l2: 0.117052    valid_1&#39;s rmse: 0.279012    valid_1&#39;s l2: 0.0778477
[120]    training&#39;s rmse: 0.339248    training&#39;s l2: 0.115089    valid_1&#39;s rmse: 0.27756    valid_1&#39;s l2: 0.0770398
[140]    training&#39;s rmse: 0.336076    training&#39;s l2: 0.112947    valid_1&#39;s rmse: 0.27745    valid_1&#39;s l2: 0.0769786
Early stopping, best iteration is:
[129]    training&#39;s rmse: 0.337326    training&#39;s l2: 0.113789    valid_1&#39;s rmse: 0.276789    valid_1&#39;s l2: 0.0766123
*****Prediction for Store: TX_1*****
Training until validation scores don&#39;t improve for 20 rounds
[20]    training&#39;s rmse: 0.779231    training&#39;s l2: 0.607202    valid_1&#39;s rmse: 0.495078    valid_1&#39;s l2: 0.245102
[40]    training&#39;s rmse: 0.734945    training&#39;s l2: 0.540143    valid_1&#39;s rmse: 0.477927    valid_1&#39;s l2: 0.228414
[60]    training&#39;s rmse: 0.715    training&#39;s l2: 0.511225    valid_1&#39;s rmse: 0.474993    valid_1&#39;s l2: 0.225618
[80]    training&#39;s rmse: 0.700945    training&#39;s l2: 0.491324    valid_1&#39;s rmse: 0.471686    valid_1&#39;s l2: 0.222487
[100]    training&#39;s rmse: 0.688138    training&#39;s l2: 0.473534    valid_1&#39;s rmse: 0.469721    valid_1&#39;s l2: 0.220638
[120]    training&#39;s rmse: 0.671506    training&#39;s l2: 0.45092    valid_1&#39;s rmse: 0.468799    valid_1&#39;s l2: 0.219772
Early stopping, best iteration is:
[111]    training&#39;s rmse: 0.678168    training&#39;s l2: 0.459912    valid_1&#39;s rmse: 0.466017    valid_1&#39;s l2: 0.217172
*****Prediction for Store: TX_2*****
Training until validation scores don&#39;t improve for 20 rounds
[20]    training&#39;s rmse: 0.949797    training&#39;s l2: 0.902115    valid_1&#39;s rmse: 0.519843    valid_1&#39;s l2: 0.270237
[40]    training&#39;s rmse: 0.901254    training&#39;s l2: 0.812259    valid_1&#39;s rmse: 0.50753    valid_1&#39;s l2: 0.257587
[60]    training&#39;s rmse: 0.860935    training&#39;s l2: 0.741208    valid_1&#39;s rmse: 0.496691    valid_1&#39;s l2: 0.246702
[80]    training&#39;s rmse: 0.837279    training&#39;s l2: 0.701036    valid_1&#39;s rmse: 0.500869    valid_1&#39;s l2: 0.25087
Early stopping, best iteration is:
[60]    training&#39;s rmse: 0.860935    training&#39;s l2: 0.741208    valid_1&#39;s rmse: 0.496691    valid_1&#39;s l2: 0.246702
*****Prediction for Store: TX_3*****
Training until validation scores don&#39;t improve for 20 rounds
[20]    training&#39;s rmse: 0.741642    training&#39;s l2: 0.550033    valid_1&#39;s rmse: 0.569192    valid_1&#39;s l2: 0.323979
[40]    training&#39;s rmse: 0.71047    training&#39;s l2: 0.504767    valid_1&#39;s rmse: 0.557032    valid_1&#39;s l2: 0.310284
[60]    training&#39;s rmse: 0.68682    training&#39;s l2: 0.471721    valid_1&#39;s rmse: 0.546532    valid_1&#39;s l2: 0.298697
[80]    training&#39;s rmse: 0.672727    training&#39;s l2: 0.452562    valid_1&#39;s rmse: 0.541006    valid_1&#39;s l2: 0.292688
[100]    training&#39;s rmse: 0.66163    training&#39;s l2: 0.437754    valid_1&#39;s rmse: 0.539347    valid_1&#39;s l2: 0.290895
[120]    training&#39;s rmse: 0.650395    training&#39;s l2: 0.423014    valid_1&#39;s rmse: 0.534985    valid_1&#39;s l2: 0.286208
[140]    training&#39;s rmse: 0.645165    training&#39;s l2: 0.416238    valid_1&#39;s rmse: 0.532259    valid_1&#39;s l2: 0.2833
Early stopping, best iteration is:
[132]    training&#39;s rmse: 0.646645    training&#39;s l2: 0.418149    valid_1&#39;s rmse: 0.531403    valid_1&#39;s l2: 0.28239
*****Prediction for Store: WI_1*****
Training until validation scores don&#39;t improve for 20 rounds
[20]    training&#39;s rmse: 0.40387    training&#39;s l2: 0.163111    valid_1&#39;s rmse: 0.351971    valid_1&#39;s l2: 0.123884
[40]    training&#39;s rmse: 0.379547    training&#39;s l2: 0.144056    valid_1&#39;s rmse: 0.339714    valid_1&#39;s l2: 0.115405
[60]    training&#39;s rmse: 0.370228    training&#39;s l2: 0.137069    valid_1&#39;s rmse: 0.338534    valid_1&#39;s l2: 0.114605
[80]    training&#39;s rmse: 0.362681    training&#39;s l2: 0.131537    valid_1&#39;s rmse: 0.335793    valid_1&#39;s l2: 0.112757
Early stopping, best iteration is:
[75]    training&#39;s rmse: 0.363574    training&#39;s l2: 0.132186    valid_1&#39;s rmse: 0.335287    valid_1&#39;s l2: 0.112418
*****Prediction for Store: WI_2*****
Training until validation scores don&#39;t improve for 20 rounds
[20]    training&#39;s rmse: 0.798844    training&#39;s l2: 0.638151    valid_1&#39;s rmse: 0.99757    valid_1&#39;s l2: 0.995147
[40]    training&#39;s rmse: 0.75986    training&#39;s l2: 0.577388    valid_1&#39;s rmse: 0.979328    valid_1&#39;s l2: 0.959084
[60]    training&#39;s rmse: 0.729671    training&#39;s l2: 0.53242    valid_1&#39;s rmse: 0.968394    valid_1&#39;s l2: 0.937787
Early stopping, best iteration is:
[57]    training&#39;s rmse: 0.732588    training&#39;s l2: 0.536685    valid_1&#39;s rmse: 0.967836    valid_1&#39;s l2: 0.936707
*****Prediction for Store: WI_3*****
Training until validation scores don&#39;t improve for 20 rounds
[20]    training&#39;s rmse: 0.803068    training&#39;s l2: 0.644919    valid_1&#39;s rmse: 0.580289    valid_1&#39;s l2: 0.336735
[40]    training&#39;s rmse: 0.762335    training&#39;s l2: 0.581154    valid_1&#39;s rmse: 0.573159    valid_1&#39;s l2: 0.328512
[60]    training&#39;s rmse: 0.739142    training&#39;s l2: 0.546331    valid_1&#39;s rmse: 0.566164    valid_1&#39;s l2: 0.320541
Early stopping, best iteration is:
[51]    training&#39;s rmse: 0.748455    training&#39;s l2: 0.560184    valid_1&#39;s rmse: 0.563976    valid_1&#39;s l2: 0.318069</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">actual = <span class="literal">False</span></span><br><span class="line"><span class="keyword">if</span> actual == <span class="literal">False</span>:</span><br><span class="line">    <span class="comment">#대회 종료 1달 전에, validation data 를 추가로 제공하기 때문에, 그 전에 training data 로만 생성한 valid 를 쓸지, 아니면 추가 제공 valid 를 쓸지 결정 </span></span><br><span class="line">    validation = sales[[<span class="string">&#x27;id&#x27;</span>]+[<span class="string">&#x27;d_&#x27;</span> + str(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1914</span>,<span class="number">1942</span>)]]</span><br><span class="line">    validation[<span class="string">&#x27;id&#x27;</span>]=pd.read_csv(<span class="string">&#x27;C:\\Eric\\Projects\\Kaggle_M5\Dataset\\sales_train_validation.csv&#x27;</span>).id</span><br><span class="line">    validation.columns=[<span class="string">&#x27;id&#x27;</span>] + [<span class="string">&#x27;F&#x27;</span> + str(i + <span class="number">1</span>) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">28</span>)]</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    valid[<span class="string">&#x27;sold&#x27;</span>] = valid_preds</span><br><span class="line">    validation = valid[[<span class="string">&#x27;id&#x27;</span>,<span class="string">&#x27;d&#x27;</span>,<span class="string">&#x27;sold&#x27;</span>]]</span><br><span class="line">    validation = pd.pivot(validation, index=<span class="string">&#x27;id&#x27;</span>, columns=<span class="string">&#x27;d&#x27;</span>, values=<span class="string">&#x27;sold&#x27;</span>).reset_index()</span><br><span class="line">    validation.columns=[<span class="string">&#x27;id&#x27;</span>] + [<span class="string">&#x27;F&#x27;</span> + str(i + <span class="number">1</span>) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">28</span>)]</span><br><span class="line">    validation.id = validation.id.map(d_id).str.replace(<span class="string">&#x27;evaluation&#x27;</span>,<span class="string">&#x27;validation&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#predictio data 생성 </span></span><br><span class="line">test[<span class="string">&#x27;sold&#x27;</span>] = eval_preds</span><br><span class="line">evaluation = test[[<span class="string">&#x27;id&#x27;</span>,<span class="string">&#x27;d&#x27;</span>,<span class="string">&#x27;sold&#x27;</span>]]</span><br><span class="line">evaluation = pd.pivot(evaluation, index=<span class="string">&#x27;id&#x27;</span>, columns=<span class="string">&#x27;d&#x27;</span>, values=<span class="string">&#x27;sold&#x27;</span>).reset_index()</span><br><span class="line">evaluation.columns=[<span class="string">&#x27;id&#x27;</span>] + [<span class="string">&#x27;F&#x27;</span> + str(i + <span class="number">1</span>) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">28</span>)]</span><br><span class="line">evaluation.id = evaluation.id.map(d_id)</span><br><span class="line"></span><br><span class="line"><span class="comment">#Submission 파일 생성 </span></span><br><span class="line">submit = pd.concat([validation,evaluation]).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">submit.to_csv(<span class="string">&#x27;M5_submission.csv&#x27;</span>,index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2020-09-21T22:05:12.000Z" title="2020-09-21T22:05:12.000Z">2020-09-22</time></span><span class="level-item">Updated&nbsp;<time dateTime="2020-09-22T05:55:40.310Z" title="2020-09-22T05:55:40.310Z">2020-09-22</time></span><span class="level-item"><a class="link-muted" href="/categories/Kaggle/">Kaggle</a></span><span class="level-item">9 minutes read (About 1327 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/09/22/project_kaggle_m5_0922/">Kaggle M5 Competition Part 1 -EDA</a></h1><div class="content"><blockquote>
<p>Contents of table:</p>
<ul>
<li><a href="#kaggle-m5-competition-part-1--eda">Kaggle M5 Competition Part 1 -EDA</a></li>
<li><a href="#1-fetch-the-data">1. Fetch the data</a></li>
<li><a href="#2-downcasting">2. Downcasting</a></li>
<li><a href="#3-exploratory-data-analysis">3. Exploratory Data Analysis</a></li>
<li><a href="#4-melting-the-data">4. Melting the data</a></li>
</ul>
</blockquote>
<hr>
<hr>
<h1 id="Kaggle-M5-Competition-Part-1-EDA"><a href="#Kaggle-M5-Competition-Part-1-EDA" class="headerlink" title="Kaggle M5 Competition Part 1 -EDA"></a>Kaggle M5 Competition Part 1 -EDA</h1><hr>
<p>미국 Wal-Mart 에서 주최한 매출예측 대회이다. </p>
<p>#ref:<br><a target="_blank" rel="noopener" href="https://mofc.unic.ac.cy/m5-competition/">https://mofc.unic.ac.cy/m5-competition/</a><br><a target="_blank" rel="noopener" href="https://www.kaggle.com/c/m5-forecasting-accuracy">https://www.kaggle.com/c/m5-forecasting-accuracy</a></p>
<p>#아래 코드는 Kaggle Grandmaster Rob Mulla 의 모델링을 기반으로 재구성하였습니다. </p>
<p>대회설명:<br>M5는 월마트에서 제공하는 계층적 판매 데이터를 사용하여, 향후 28 일 동안의 일일 판매를 예측하고 분포를 추정하는 것이 목표이다.<br>데이터에는 가격, 프로모션, 요일 및 특별 이벤트와 같은 설명 변수가 포함된다.  </p>
<p>데이터셋:<br>calendar.csv               - 제품 판매 날짜에 대한 정보를 포함.<br>sales_train_validation.csv - 제품 및 매장 별 일일 판매량 기록 데이터 포함 [d_1-d_1913]<br>sample_submission.csv      - 제출 양식.<br>sell_prices.csv            - 상점 및 날짜별로 판매 된 제품의 가격에 대한 정보를 포함.<br>sales_train_evaluation.cs  - 제품 판매 포함 [d_1-d_1941] </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> plotly_express <span class="keyword">as</span> px</span><br><span class="line"><span class="keyword">import</span> plotly.graph_objects <span class="keyword">as</span> go</span><br><span class="line"><span class="keyword">from</span> plotly.subplots <span class="keyword">import</span> make_subplots</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> gc</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line"><span class="keyword">from</span> lightgbm <span class="keyword">import</span> LGBMRegressor</span><br><span class="line"><span class="keyword">import</span> joblib</span><br></pre></td></tr></table></figure>

<h1 id="1-Fetch-the-data"><a href="#1-Fetch-the-data" class="headerlink" title="1. Fetch the data"></a>1. Fetch the data</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sales = pd.read_csv(<span class="string">&#x27;C:\\Eric\\Projects\\Kaggle_M5\Dataset\\sales_train_evaluation.csv&#x27;</span>)</span><br><span class="line">sales.name = <span class="string">&#x27;sales&#x27;</span></span><br><span class="line">calendar = pd.read_csv(<span class="string">&#x27;C:\\Eric\\Projects\\Kaggle_M5\Dataset\\calendar.csv&#x27;</span>)</span><br><span class="line">calendar.name = <span class="string">&#x27;calendar&#x27;</span></span><br><span class="line">prices = pd.read_csv(<span class="string">&#x27;C:\\Eric\\Projects\\Kaggle_M5\Dataset\\sell_prices.csv&#x27;</span>)</span><br><span class="line">prices.name = <span class="string">&#x27;prices&#x27;</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sales.columns</span><br></pre></td></tr></table></figure>




<pre><code>Index([&#39;id&#39;, &#39;item_id&#39;, &#39;dept_id&#39;, &#39;cat_id&#39;, &#39;store_id&#39;, &#39;state_id&#39;, &#39;d_1&#39;,
       &#39;d_2&#39;, &#39;d_3&#39;, &#39;d_4&#39;,
       ...
       &#39;d_1932&#39;, &#39;d_1933&#39;, &#39;d_1934&#39;, &#39;d_1935&#39;, &#39;d_1936&#39;, &#39;d_1937&#39;, &#39;d_1938&#39;,
       &#39;d_1939&#39;, &#39;d_1940&#39;, &#39;d_1941&#39;],
      dtype=&#39;object&#39;, length=1947)</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#빈 칸 처리되어있는 d 1942 ~ 1969 col들에 0 입력</span></span><br><span class="line"><span class="keyword">for</span> d <span class="keyword">in</span> range(<span class="number">1942</span>,<span class="number">1970</span>):</span><br><span class="line">    col = <span class="string">&#x27;d_&#x27;</span> + str(d)</span><br><span class="line">    sales[col] = <span class="number">0</span></span><br><span class="line">    sales[col] = sales[col].astype(np.int16)</span><br></pre></td></tr></table></figure>

<h1 id="2-Downcasting"><a href="#2-Downcasting" class="headerlink" title="2. Downcasting"></a>2. Downcasting</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#기본 데이터셋의 용량이 큰 만큼, 메모리 다운이 필요. </span></span><br><span class="line">sales_bd = np.round(sales.memory_usage().sum()/(<span class="number">1024</span>*<span class="number">1024</span>),<span class="number">1</span>)</span><br><span class="line">calendar_bd = np.round(calendar.memory_usage().sum()/(<span class="number">1024</span>*<span class="number">1024</span>),<span class="number">1</span>)</span><br><span class="line">prices_bd = np.round(prices.memory_usage().sum()/(<span class="number">1024</span>*<span class="number">1024</span>),<span class="number">1</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#캐글의 memory downcasting 코드를 참고하여 아래와 같이 메모리 다운. </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">downcast</span>(<span class="params">df</span>):</span></span><br><span class="line">    cols = df.dtypes.index.tolist()</span><br><span class="line">    types = df.dtypes.values.tolist()</span><br><span class="line">    <span class="keyword">for</span> i,t <span class="keyword">in</span> enumerate(types):</span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;int&#x27;</span> <span class="keyword">in</span> str(t):</span><br><span class="line">            <span class="keyword">if</span> df[cols[i]].min() &gt; np.iinfo(np.int8).min <span class="keyword">and</span> df[cols[i]].max() &lt; np.iinfo(np.int8).max:</span><br><span class="line">                df[cols[i]] = df[cols[i]].astype(np.int8)</span><br><span class="line">            <span class="keyword">elif</span> df[cols[i]].min() &gt; np.iinfo(np.int16).min <span class="keyword">and</span> df[cols[i]].max() &lt; np.iinfo(np.int16).max:</span><br><span class="line">                df[cols[i]] = df[cols[i]].astype(np.int16)</span><br><span class="line">            <span class="keyword">elif</span> df[cols[i]].min() &gt; np.iinfo(np.int32).min <span class="keyword">and</span> df[cols[i]].max() &lt; np.iinfo(np.int32).max:</span><br><span class="line">                df[cols[i]] = df[cols[i]].astype(np.int32)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                df[cols[i]] = df[cols[i]].astype(np.int64)</span><br><span class="line">        <span class="keyword">elif</span> <span class="string">&#x27;float&#x27;</span> <span class="keyword">in</span> str(t):</span><br><span class="line">            <span class="keyword">if</span> df[cols[i]].min() &gt; np.finfo(np.float16).min <span class="keyword">and</span> df[cols[i]].max() &lt; np.finfo(np.float16).max:</span><br><span class="line">                df[cols[i]] = df[cols[i]].astype(np.float16)</span><br><span class="line">            <span class="keyword">elif</span> df[cols[i]].min() &gt; np.finfo(np.float32).min <span class="keyword">and</span> df[cols[i]].max() &lt; np.finfo(np.float32).max:</span><br><span class="line">                df[cols[i]] = df[cols[i]].astype(np.float32)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                df[cols[i]] = df[cols[i]].astype(np.float64)</span><br><span class="line">        <span class="keyword">elif</span> t == np.object:</span><br><span class="line">            <span class="keyword">if</span> cols[i] == <span class="string">&#x27;date&#x27;</span>:</span><br><span class="line">                df[cols[i]] = pd.to_datetime(df[cols[i]], format=<span class="string">&#x27;%Y-%m-%d&#x27;</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                df[cols[i]] = df[cols[i]].astype(<span class="string">&#x27;category&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> df  </span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sales = downcast(sales)</span><br><span class="line">prices = downcast(prices)</span><br><span class="line">calendar = downcast(calendar)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#메모리 다운 후의 메모리 사용량 체크. </span></span><br><span class="line">sales_ad = np.round(sales.memory_usage().sum()/(<span class="number">1024</span>*<span class="number">1024</span>),<span class="number">1</span>)</span><br><span class="line">calendar_ad = np.round(calendar.memory_usage().sum()/(<span class="number">1024</span>*<span class="number">1024</span>),<span class="number">1</span>)</span><br><span class="line">prices_ad = np.round(prices.memory_usage().sum()/(<span class="number">1024</span>*<span class="number">1024</span>),<span class="number">1</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#다운 캐스팅이 DataFrame의 메모리 사용량에 얼마나 많은 영향을 미쳤는지 시각화.1/4 미만으로 줄일 수 있음. </span></span><br><span class="line">dic = &#123;<span class="string">&#x27;DataFrame&#x27;</span>:[<span class="string">&#x27;sales&#x27;</span>,<span class="string">&#x27;calendar&#x27;</span>,<span class="string">&#x27;prices&#x27;</span>],</span><br><span class="line">       <span class="string">&#x27;Before downcasting&#x27;</span>:[sales_bd,calendar_bd,prices_bd],</span><br><span class="line">       <span class="string">&#x27;After downcasting&#x27;</span>:[sales_ad,calendar_ad,prices_ad]&#125;</span><br><span class="line"></span><br><span class="line">memory = pd.DataFrame(dic)</span><br><span class="line">memory = pd.melt(memory, id_vars=<span class="string">&#x27;DataFrame&#x27;</span>, var_name=<span class="string">&#x27;Status&#x27;</span>, value_name=<span class="string">&#x27;Memory (MB)&#x27;</span>)</span><br><span class="line">memory.sort_values(<span class="string">&#x27;Memory (MB)&#x27;</span>,inplace=<span class="literal">True</span>)</span><br><span class="line">fig = px.bar(memory, x=<span class="string">&#x27;DataFrame&#x27;</span>, y=<span class="string">&#x27;Memory (MB)&#x27;</span>, color=<span class="string">&#x27;Status&#x27;</span>, barmode=<span class="string">&#x27;group&#x27;</span>, text=<span class="string">&#x27;Memory (MB)&#x27;</span>)</span><br><span class="line">fig.update_traces(texttemplate=<span class="string">&#x27;%&#123;text&#125; MB&#x27;</span>, textposition=<span class="string">&#x27;outside&#x27;</span>)</span><br><span class="line">fig.update_layout(template=<span class="string">&#x27;seaborn&#x27;</span>, title=<span class="string">&#x27;Effect of Downcasting&#x27;</span>)</span><br><span class="line">fig.show()</span><br></pre></td></tr></table></figure>

<p><img src="https://github.com/jeantirole/Project_M5/blob/master/effect%20of%20downcasting.png?raw=true"></p>
<h1 id="3-Exploratory-Data-Analysis"><a href="#3-Exploratory-Data-Analysis" class="headerlink" title="3. Exploratory Data Analysis"></a>3. Exploratory Data Analysis</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">walmart 에서 제공하는 세일즈 데이터는, wrt, 즉 with respect to [ cols ]</span><br><span class="line">State: CA, WI, TX  (3)</span><br><span class="line">Store: CA_1, CA_2, TX_1, WI_1, ... (10)</span><br><span class="line">Category: FOOD, HOBBIES, HOUSEHOLD (3) </span><br><span class="line">Department:FOOD_1,2,3 , HOBBIES_1,2, ... (7)</span><br><span class="line">item_id:: each unique id # (3,049)</span><br></pre></td></tr></table></figure>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#plotly_express 에서 제공하는 treemap 을 활용해서, 각 제품 id 를 count var로 잡고, data col 들의 관계를 directory 형태로 시각화.</span></span><br><span class="line"></span><br><span class="line">group = sales.groupby([<span class="string">&#x27;state_id&#x27;</span>,<span class="string">&#x27;store_id&#x27;</span>,<span class="string">&#x27;cat_id&#x27;</span>,<span class="string">&#x27;dept_id&#x27;</span>],as_index=<span class="literal">False</span>)[<span class="string">&#x27;item_id&#x27;</span>].count().dropna()</span><br><span class="line">group[<span class="string">&#x27;USA&#x27;</span>] = <span class="string">&#x27;United States of America&#x27;</span></span><br><span class="line">group.rename(columns=&#123;<span class="string">&#x27;state_id&#x27;</span>:<span class="string">&#x27;State&#x27;</span>,<span class="string">&#x27;store_id&#x27;</span>:<span class="string">&#x27;Store&#x27;</span>,<span class="string">&#x27;cat_id&#x27;</span>:<span class="string">&#x27;Category&#x27;</span>,<span class="string">&#x27;dept_id&#x27;</span>:<span class="string">&#x27;Department&#x27;</span>,<span class="string">&#x27;item_id&#x27;</span>:<span class="string">&#x27;Count&#x27;</span>&#125;,inplace=<span class="literal">True</span>)</span><br><span class="line">fig = px.treemap(group, path=[<span class="string">&#x27;USA&#x27;</span>, <span class="string">&#x27;State&#x27;</span>, <span class="string">&#x27;Store&#x27;</span>, <span class="string">&#x27;Category&#x27;</span>, <span class="string">&#x27;Department&#x27;</span>], values=<span class="string">&#x27;Count&#x27;</span>,</span><br><span class="line">                  color=<span class="string">&#x27;Count&#x27;</span>,</span><br><span class="line">                  color_continuous_scale= px.colors.sequential.Sunset,</span><br><span class="line">                  title=<span class="string">&#x27;Walmart: Distribution of items&#x27;</span>)</span><br><span class="line">fig.update_layout(template=<span class="string">&#x27;seaborn&#x27;</span>)</span><br><span class="line">fig.show()</span><br></pre></td></tr></table></figure>

<p><img src="https://github.com/jeantirole/Project_M5/blob/master/distribution%20of%20items.png?raw=true"></p>
<h1 id="4-Melting-the-data"><a href="#4-Melting-the-data" class="headerlink" title="4. Melting the data"></a>4. Melting the data</h1><p>#4.1 Convert from wide to long format</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">머신러닝 포맷에 적합시키기 위해서는 와이드 형식의 판매 데이터 프레임을 긴 형식으로 변환이 필요하다. sales 데이터셋의 row 는 30490(&#x3D;&#x3D; # of items), 데이터셋을 melt하게되면은 sales, calendar 30490 x 1969 &#x3D; 60034810 개의 row 를 가지게 된다. </span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df = pd.melt(sales, id_vars=[<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;item_id&#x27;</span>, <span class="string">&#x27;dept_id&#x27;</span>, <span class="string">&#x27;cat_id&#x27;</span>, <span class="string">&#x27;store_id&#x27;</span>, <span class="string">&#x27;state_id&#x27;</span>], var_name=<span class="string">&#x27;d&#x27;</span>, value_name=<span class="string">&#x27;sold&#x27;</span>).dropna()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df = pd.merge(df, calendar, on=<span class="string">&#x27;d&#x27;</span>, how=<span class="string">&#x27;left&#x27;</span>)</span><br><span class="line">df = pd.merge(df, prices, on=[<span class="string">&#x27;store_id&#x27;</span>,<span class="string">&#x27;item_id&#x27;</span>,<span class="string">&#x27;wm_yr_wk&#x27;</span>], how=<span class="string">&#x27;left&#x27;</span>) </span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Store 별로 매출액합계를 violin plot 을 활용해서 시각화. </span></span><br><span class="line">group = df.groupby([<span class="string">&#x27;year&#x27;</span>,<span class="string">&#x27;date&#x27;</span>,<span class="string">&#x27;state_id&#x27;</span>,<span class="string">&#x27;store_id&#x27;</span>], as_index=<span class="literal">False</span>)[<span class="string">&#x27;sold&#x27;</span>].sum().dropna()</span><br><span class="line">fig = px.violin(group, x=<span class="string">&#x27;store_id&#x27;</span>, color=<span class="string">&#x27;state_id&#x27;</span>, y=<span class="string">&#x27;sold&#x27;</span>,box=<span class="literal">True</span>)</span><br><span class="line">fig.update_xaxes(title_text=<span class="string">&#x27;Store&#x27;</span>)</span><br><span class="line">fig.update_yaxes(title_text=<span class="string">&#x27;Total items sold&#x27;</span>)</span><br><span class="line">fig.update_layout(template=<span class="string">&#x27;seaborn&#x27;</span>,title=<span class="string">&#x27;Distribution of Items sold wrt Stores&#x27;</span>,legend_title_text=<span class="string">&#x27;State&#x27;</span>)</span><br><span class="line">fig.show()</span><br></pre></td></tr></table></figure>

<p><img src="https://github.com/jeantirole/Project_M5/blob/master/distribution%20of%20items%20sold%20wrt%20stores.png?raw=true"></p>
</div></article></div><nav class="pagination is-centered mt-4" role="navigation" aria-label="pagination"><div class="pagination-previous is-invisible is-hidden-mobile"><a href="/page/0/">Previous</a></div><div class="pagination-next"><a href="/page/2/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link is-current" href="/">1</a></li><li><a class="pagination-link" href="/page/2/">2</a></li><li><a class="pagination-link" href="/page/3/">3</a></li><li><a class="pagination-link" href="/page/4/">4</a></li></ul></nav></div><!--!--><div class="column column-right is-4-tablet is-4-desktop is-4-widescreen  order-3"><div class="card widget"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="Eric"></figure><p class="title is-size-4 is-block line-height-inherit">Eric</p><p class="is-size-6 is-block">Developer blog</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Seonyudo</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">8</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">3</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tag</p><a href="/tags"><p class="title">1</p></a></div></div></nav><div class="level"><a class="level-item button has-background-warning" href="/" target="_blank" rel="noopener">Have a nice day</a></div></div></div><!--!--><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/categories/Kaggle/"><span class="level-start"><span class="level-item">Kaggle</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Python/"><span class="level-start"><span class="level-item">Python</span></span><span class="level-end"><span class="level-item tag">6</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/Python/Cos-Pro-1%EA%B8%89/"><span class="level-start"><span class="level-item">Cos Pro 1급</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li></ul></li></ul></div></div></div><div class="card widget"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content size-small"><p><time dateTime="2020-09-22T00:05:12.000Z">2020-09-22</time></p><p class="title is-6"><a class="link-muted" href="/2020/09/22/project_kaggle_m5_0922%20Modeling/">Kaggle M5 Competition Part 2 -Modeling</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Kaggle/">Kaggle</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-09-21T22:05:12.000Z">2020-09-22</time></p><p class="title is-6"><a class="link-muted" href="/2020/09/22/project_kaggle_m5_0922/">Kaggle M5 Competition Part 1 -EDA</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Kaggle/">Kaggle</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-09-21T05:05:12.000Z">2020-09-21</time></p><p class="title is-6"><a class="link-muted" href="/2020/09/21/1%EA%B8%89-1%EC%B0%A8-05%EB%B2%88/">Cos Pro Python 1급 1차 05번 문제풀이</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Python/">Python</a> / <a class="link-muted" href="/categories/Python/Cos-Pro-1%EA%B8%89/">Cos Pro 1급</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-09-21T04:05:12.000Z">2020-09-21</time></p><p class="title is-6"><a class="link-muted" href="/2020/09/21/1%EA%B8%89-1%EC%B0%A8-06%EB%B2%88/">Cos Pro Python 1급 1차 06번 문제풀이</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Python/">Python</a> / <a class="link-muted" href="/categories/Python/Cos-Pro-1%EA%B8%89/">Cos Pro 1급</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-09-21T03:05:12.000Z">2020-09-21</time></p><p class="title is-6"><a class="link-muted" href="/2020/09/21/1%EA%B8%89-1%EC%B0%A8-04%EB%B2%88/">Cos Pro Python 1급 1차 04번 문제풀이</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Python/">Python</a> / <a class="link-muted" href="/categories/Python/Cos-Pro-1%EA%B8%89/">Cos Pro 1급</a></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/archives/2020/09/"><span class="level-start"><span class="level-item">September 2020</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Python/"><span class="tag">Python</span><span class="tag is-grey-lightest">8</span></a></div></div></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button is-primary" type="submit" value="Subscribe"></div></div></form></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="" height="28"></a><p class="size-small"><span>&copy; 2020 Eric Park</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" async></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><!--!--></body></html>