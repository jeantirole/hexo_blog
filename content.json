{"pages":[],"posts":[{"title":"Cos Pro Python 1급 1차 01번 문제풀이","text":"Contents of table: 문제내용 정답코드 Topic:배달음식점 주문메뉴 만들기 Description:파이썬의 전형적인 메뉴판 만들기 문제를, 클래스를 활용해서 작성할 수 있는가를테스트 하는 문제이다. 해당 문제는 특히 추상클래스에 대한 이해 여부가 포인트이다.논리구조는 특별할 것이 없다. 문제내용 DeliveryStore : DeliveryStore는 배달 음식점의 인터페이스입니다. 배달 음식점은 set_order_list와 get_total_price 함수를 구현해야 합니다. set_order_list 함수는 주문 메뉴의 리스트를 매개변수로 받아 저장합니다. get_total_price 함수는 주문받은 음식 가격의 총합을 return 합니다. Food : Food는 음식을 나타내는 클래스입니다. 음식은 이름(name)과 가격(price)으로 구성되어있습니다. PizzaStore PizzaStore는 피자 배달 전문점을 나타내는 클래스이며 DeliveryStore 인터페이스를 구현합니다. menu_list는 피자 배달 전문점에서 주문 할 수 있는 음식의 리스트를 저장합니다. order_list는 주문 받은 음식들의 이름을 저장합니다. set_order_list 함수는 주문 메뉴를 받아 order_list에 저장합니다. get_total_price 함수는 order_list에 들어있는 음식 가격의 총합을 return 합니다. 주문 메뉴가 들어있는 리스트 order_list가 매개변수로 주어질 때, 주문한 메뉴의 전체 가격을 return 하도록 solution 함수를 작성하려고 합니다. 위의 클래스 구조를 참고하여 주어진 코드의 빈칸을 적절히 채워 전체 코드를 완성해주세요. 매개변수 설명주문 메뉴가 들어있는 리스트 order_list가 solution 함수의 매개변수로 주어집니다. order_list의 길이는 1 이상 5이하입니댜. order_list에는 주문하려는 메뉴의 이름들이 문자열 형태로 들어있습니다. order_list에는 같은 메뉴의 이름이 중복해서 들어있지 않습니다. 메뉴의 이름과 가격은 PizzaStore의 생성자에서 초기화해줍니다. return 값 설명주문한 메뉴의 전체 가격을 return 해주세요. 예시 order_list return [“Cheese”, “Pineapple”, “Meatball”] 51600 정답코드 1from abc import * # 추상클래스 import 12345678class DeliveryStore(metaclass=ABCMeta): # 추상클래스에 앞으로 만들 함수목록 지정 @abstractmethod def set_order_list(self, order_list): pass @abstractmethod def get_total_price(self): pass 1234class Food: # name, price 변수를 만들어줄 class 작성 def __init__(self, name, price): self.name = name self.price = price 123456789101112131415161718192021class PizzaStore(DeliveryStore): # (name, price)가 리스트의 요소로 이루어진 menu_list def __init__(self): menu_names = [&quot;Cheese&quot;, &quot;Potato&quot;, &quot;Shrimp&quot;, &quot;Pineapple&quot;, &quot;Meatball&quot;] menu_prices = [11100, 12600, 13300, 21000, 19500]; self.menu_list = [] for i in range(5): self.menu_list.append(Food(menu_names[i], menu_prices[i])) self.order_list = [] def set_order_list(self, order_list): # order_list 변수작성 for order in order_list: self.order_list.append(order) def get_total_price(self): # menu_list의 name변수와 order_list의 요소를 비교하여 동일 요소일 경우, price 값을 total_price에 누적합 return total_price = 0 for order in self.order_list: for menu in self.menu_list: if order == menu.name: total_price += menu.price return total_price 123456def solution(order_list): #order_list를 넣었을 때, total price가 나올 수 있도록 마무리 delivery_store = PizzaStore() delivery_store.set_order_list(order_list) total_price = delivery_store.get_total_price() return total_price","link":"/2020/09/18/1%EA%B8%89-1%EC%B0%A8-01%EB%B2%88/"},{"title":"Cos Pro Python 1급 1차 02번 문제풀이","text":"Contents of table: 문제내용 정답코드 Topic:해밍거리 구하기 Review:주어진 두 개의 문자열 리스트의 길이를 활용하고 인덱스값을 이용해서 두 리스트의 요소들을 비교할 수 있는가?라는 것을 묻는 문제이다. 문제내용#문제2해밍 거리(Hamming distance)란 같은 길이를 가진 두 개의 문자열에서 같은 위치에 있지만 서로 다른 문자의 개수를 뜻합니다. 예를 들어 두 2진수 문자열이 “10010”과 “110”이라면, 먼저 두 문자열의 자릿수를 맞추기 위해 “110”의 앞에 0 두개를 채워 “00110”으로 만들어 줍니다. 두 2진수 문자열은 첫 번째와 세 번째 문자가 서로 다르므로 해밍 거리는 2입니다. 1001 0 0011 0 두 2진수 문자열 binaryA, binaryB의 해밍 거리를 구하려 합니다. 이를 위해 다음과 같이 간단히 프로그램 구조를 작성했습니다 12341단계. 길이가 더 긴 2진수 문자열의 길이를 구합니다.2단계. 첫 번째 2진수 문자열의 길이가 더 짧다면 문자열의 앞에 0을 채워넣어 길이를 맞춰줍니다.3단계. 두 번째 2진수 문자열의 길이가 더 짧다면 문자열의 앞에 0을 채워넣어 길이를 맞춰줍니다.4단계. 길이가 같은 두 2진수 문자열의 해밍 거리를 구합니다. 두 2진수 문자열 binaryA와 binaryB가 매개변수로 주어질 때, 두 2진수의 해밍 거리를 return 하도록 solution 함수를 작성했습니다. 이때, 위 구조를 참고하여 중복되는 부분은 func_a라는 함수로 작성했습니다. 코드가 올바르게 동작할 수 있도록 빈칸을 알맞게 채워 전체 코드를 완성해주세요. 매개변수 설명두 2진수 문자열 binaryA와 binaryB가 solution 함수의 매개변수로 주어집니다. binaryA의 길이는 1 이상 10 이하입니다. binaryA는 0 또는 1로만 이루어진 문자열이며, 0으로 시작하지 않습니다. binaryB의 길이는 1 이상 10 이하입니다. binaryB는 0 또는 1로만 이루어진 문자열이며, 0으로 시작하지 않습니다. return 값 설명두 2진수 문자열의 해밍 거리를 return 해주세요. 예시 binaryA binaryB return “10010” “110” 2 예시 설명두 2진수의 자릿수는 각각 5와 3입니다. 자릿수를 맞추기 위해 “110” 앞에 0 두 개를 채워주면 “00110”이 됩니다. 이제 두 2진수 문자열의 해밍 거리를 구하면 다음과 같습니다. 1001 0 0011 0 위와 같이 첫 번째와 세 번째 문자가 서로 다르므로, 해밍 거리는 2가 됩니다. 정답코드123456def func_a(bstr, bstr_len): # 문자열의 부족한 길이만큼의 0문자열을 추가하다 padZero = &quot;&quot; #빈 문자열 padSize = bstr_len - len(bstr) #매개변수로 주어진 문자열과, 주어진 문자열 만큼의 차이 for i in range(padSize): #위의 차이 만큼의 문자열 &quot;0&quot;을 빈 문자열 안에 넣어준다. padZero += &quot;0&quot; return padZero + bstr # 변수로 주어진 문자열에, &quot;0&quot;으로 채워진 문자열을 추가한다. 123456789101112def solution(binaryA, binaryB): max_length = max(len(binaryA), len(binaryB)) #두 문자열의 길이 중 더 큰 것을 고른다. if max_length &gt; len(binaryA): #binaryA가 더 작을 경우에, func_a를 이용해서 &quot;0&quot; 문자열을 추가해서 반환해준다. binaryA = func_a(binaryA, max_length) if max_length &gt; len(binaryB): #binaryB가 더 작을 경우. 위와동일. binaryB = fucn_a(binaryB, max_length) hamming_distance = 0 for i in range(max_length): #두 매개변수의 요소들을 훑기 위한 for문. if binaryA[i] != binaryB[i]: hamming_distance += 1 #해밍거리 count return hamming_distance","link":"/2020/09/19/1%EA%B8%89-1%EC%B0%A8-02%EB%B2%88/"},{"title":"Cos Pro Python 1급 1차 03번 문제풀이","text":"Contents of table: 문제내용 정답코드 Topic:계산기 by 문자열 Review:‘enumerate()’ 함수를 적극적으로 활용함. 개인적으로 func_c의 slicing 아이디어가 좋았다. 문제내용문자열 형태의 식을 계산하려 합니다. 식은 2개의 자연수와 1개의 연산자(‘+’, ‘-‘, ‘*’ 중 하나)로 이루어져 있습니다. 예를 들어 주어진 식이 “123+12”라면 이를 계산한 결과는 135입니다. 문자열로 이루어진 식을 계산하기 위해 다음과 같이 간단히 프로그램 구조를 작성했습니다. 1단계. 주어진 식에서 연산자의 위치를 찾습니다.2단계. 연산자의 앞과 뒤에 있는 문자열을 각각 숫자로 변환합니다.3단계. 주어진 연산자에 맞게 연산을 수행합니다. 문자열 형태의 식 expression이 매개변수로 주어질 때, 식을 계산한 결과를 return 하도록 solution 함수를 작성하려 합니다. 위 구조를 참고하여 코드가 올바르게 동작할 수 있도록 빈칸에 주어진 func_a, func_b, func_c 함수와 매개변수를 알맞게 채워주세요. 매개변수 설명문자열 형태의 식 expression이 solution 함수의 매개변수로 주어집니다. expression은 연산자 1개와 숫자 2개가 결합한 형태입니다. 연산자는 ‘+’, ‘-‘, ‘*’만 사용됩니다. 숫자는 1 이상 10,000 이하의 자연수입니다. return 값 설명expression을 계산한 결과를 return 해주세요. 계산 결과는 문자열로 변환하지 않아도 됩니다. 예시 expression return “123+12” 135 예시 설명‘+’를 기준으로 앞의 숫자는 123이고 뒤의 숫자는 12이므로 두 숫자를 더하면 135가 됩니다. 정답코드12345678910111213def func_a(numA, numB, exp): #주어진 문자열에서 사칙연산 기호를 찾아서, 해당 연산실행 if exp == '+': return numA + numB elif exp == '-': return numA - numB elif exp == '*': return numA * numB~~~ ~~~pythondef func_b(exp): #리스트 변수를 idx 와 val로 나누고, 연산기호의 idx 값을 return for index, value in enumerate(exp): if value == '+' or value == '-' or value == '*': return index 1234def func_c(exp, idx): #주어진 연산자의 앞과 뒤의 문자열을 숫자로 반환 numA = int(exp[:idx]) numB = int(exp[idx + 1:]) return numA, numB 12345def solution(expression): exp_index = func_b(expression) #연산 기호의 idx 값을 exp_index 변수에 저장 first_num, second_num = func_c(expression, exp_index) result = func_a(first_num, second_num, expression[exp_index]) return result","link":"/2020/09/20/1%EA%B8%89-1%EC%B0%A8-03%EB%B2%88/"},{"title":"Cos Pro Python 1급 1차 04번 문제풀이","text":"Contents of table: 문제내용 정답코드 Topic:타임머신 Review:#point 1) 연산자의 활용능력. 기호 //, % 을 활용할 수 있는가.#point 2) 숫자에 0을 포함하지 않도록 하는 로직. 정답코드에서는 num // digit % 10 == 0 으로 판단기준을 잡았다. 0이 포함된 숫자는 10의 배수라는 아이디어를 기본으로 num +=1, digit *= 10 을 반복하며 각 자릿수마다 0 이 없도록 while 문을 반복시킴. 문제내용어느 누군가가 타임머신을 타고 과거로 가서 숫자 0이 없는 수 체계를 전파했습니다. 역사가 바뀌어 이제 사람들의 의식 속엔 0이란 숫자가 사라졌습니다. 따라서, 현재의 수 체계는 1, 2, 3, …, 8, 9, 11, 12, …와 같이 0이 없게 바뀌었습니다. 0을 포함하지 않은 자연수 num이 매개변수로 주어질 때, 이 수에 1을 더한 수를 return 하도록 solution 함수를 완성해주세요. 매개변수 설명자연수 num이 solution 함수의 매개변수로 주어집니다. num은 1 이상 999,999,999,999,999,999 이하의 0을 포함하지 않는 자연수입니다. return 값 설명자연수 num에 1을 더한 수를 return 해주세요. 예시 num return 9949999 9951111 예시 설명9,949,999에 1을 더하면 9,950,000이지만 0은 존재하지 않으므로 9,951,111이 됩니다. 정답코드 def solution(num): num += 1 #100을 넣었다고 가정해 볼 때, 101 즉 끝자리 수의 0을 1로 바꿔준다. digit = 1 #임의의 digit 값, 아래 함수 참조하면, 1 =&gt; 10 =&gt; 100, 10의 거듭제곱 형태. while num // digit % 10 == 0: # num 값이 10의 배수라고 가정 했을 때, num += digit digit *= 10 return num ~~~python ## **부가설명** num에 99라는 값을 임의로 넣었다고 가정했을 때, 아래와 같은 연산이 진행이 된다. num = 99 digit =1 num += 1 =&gt; num = 100 #99라는 숫자에 1을 더했을 때, 10의 배수가 되는데, 10의 배수가 되지 않도록 만드는 것이 목표. num // digit % 10 == 0 (true) #100은 10의 배수 이므로 (num//digit) 값의 나머지가 0이 된다. 100 + 1 = 101 = num #100에서 바꾸어야 할 숫자는 10**0자리와 10**1자리 둘. 두 개중 하나가 해결되었다. 1 * 10 = 10 = digit #10**0의 자리수가 해결이 되었으므로 10**1자리로 포인트 이동. 101 // 10 % 10 == 0 (true) #101은 여전히 10의 배수, 몫의 정수 부분이 10이다. 101 + 10 = 111 = num #한 자리 수 올라간 digit 부분이 10*1 부분에 1을 삽입. 10 * 10 = 100 = digit 111 // 10 % 10 == 0 (false) #루프 break","link":"/2020/09/21/1%EA%B8%89-1%EC%B0%A8-04%EB%B2%88/"},{"title":"Cos Pro Python 1급 1차 05번 문제풀이","text":"Contents of table: 문제내용 정답코드 Topic:소용돌이 수 Review:유명한 소용돌이 알고리즘 문제이다. 2차원 리스트 안에서, 원하는 대로 point 이동 알고리즘을 짤 수 있는가를 테스트하는 문제이다. 정답코드 12def in_range(i, j, n): # i와 j값이 0보다크고 n보다 작은지 확인 return 0 &lt;= i and i &lt; n and 0 &lt;= j and j &lt; n 12345678910111213141516171819202122def solution(n): pane = [[0 for j in range(n)] for i in range(n)] # n * n 크기의 panel 을 만든다. dy = [0, 1, 0, -1] # 2차원 리스트 panel 에서, (dy,dx)의 움직임은, (right, down, left, up)을 의미한다. dx = [1, 0, -1, 0] ci, cj = 0, 0 # 시작 포인트는 (0,0) num = 1 while in_range(ci, cj, n) and pane[ci][cj] == 0: # 1) in_range 함수를 활용, current point가 panel을 벗어나지 않음. 2) 이동하는 칸에 숫자가 채워져 있지 않음. for k in range(4): # dy, dx의 이동순서 if not in_range(ci, cj, n) or pane[ci][cj] != 0: break while True: # 1) pannel 범위안 2) 다음칸의 숫자가 비어있을 때, 무한루프 pane[ci][cj] = num # k = 0 일 때, panel의 범위 안에서 num +=1 만큼의 숫자를 각 칸에 입력 num += 1 ni = ci + dy[k] # next point는 current point 에서 (dy,dx) 만큼의 이동값을 가져간 결과이다. nj = cj + dx[k] if not in_range(ni, nj, n) or pane[ni][nj] != 0: # next point 가 pannel 을 벗어났을 경우, (down, left, up, right) 순서로 이동. ci += dy[(k + 1) % 4] # (k+1) % 4 는 1 2 3 0 cj += dx[(k + 1) % 4] break ci = ni cj = nj return pane 문제내용#문제5다음과 같이 n x n 크기의 격자에 1부터 n x n까지의 수가 하나씩 있습니다. 이때 수가 다음과 같은 순서로 배치되어있다면 이것을 n-소용돌이 수라고 부릅니다. 소용돌이 수에서 1행 1열부터 n 행 n 열까지 대각선상에 존재하는 수들의 합을 구해야 합니다. 위의 예에서 대각선상에 존재하는 수의 합은 15입니다.격자의 크기 n이 주어질 때 n-소용돌이 수의 대각선상에 존재하는 수들의 합을 return 하도록 solution 함수를 완성해주세요. 매개변수 설명격자의 크기 n이 solution 함수의 매개변수로 주어집니다. n은 1 이상 100 이하의 자연수입니다. return 값 설명n-소용돌이 수의 대각선상에 존재하는 수들의 합을 return 해주세요. 예시 n return 3 15 2 4 예시 설명예시 #1문제의 예와 같습니다. 예시 #21과 3을 더하여 4가 됩니다.","link":"/2020/09/21/1%EA%B8%89-1%EC%B0%A8-05%EB%B2%88/"},{"title":"Cos Pro Python 1급 1차 06번 문제풀이","text":"Contents of table: 문제내용 정답코드 Topic:체스의 나이트 Review:2차원 panel 위에서 포인트 이동문제.소용돌이 알고리즘의 해결방법과 유사하게, direction 리스트를 정하고, point 를 정해진 조건에따라서 이동시켜서 결과값을 얻어낸다. 정답코드 12345678910111213def solution(pos): dx = [1,1,-1,-1,2,2,-2,-2] #체스말이 움직이는 거리와 방향을 나타낸다. dy = [2,-2,-2,2,1,-1,-1,1] #ex) (x,y) =&gt; (x+dx, y+dy) cx = ord(pos[0]) - ord(&quot;A&quot;) #ord()함수는 문자열의 unicode 값을 리턴해준다. #체스판 구조상, A와 1을 기준으로 잡고, unicode의 차이만큼을 current position으로 보겠다는 의미. cy = ord(pos[1]) - ord(&quot;0&quot;) - 1 ans = 0 for i in range(8): #나이트가 움직일 수 있는 전방위는 8가지이다. nx = cx + dx[i] #ex) (nx,ny) =&gt; (x+dx, y+dy) ny = cy + dy[i] if nx &gt;= 0 and nx &lt; 8 and ny &gt;= 0 and ny &lt; 8: # 0 &lt;= x,y &lt; 8 이어야지 체스판을 벗어나지 않는다. ans += 1 # nx, ny 가 체스판을 벗어나지 않을 경우, ans 변수에 카운트누적. return ans 문제내용체스에서 나이트(knight)는 아래 그림과 같이 동그라미로 표시된 8개의 방향중 한 곳으로 한 번에 이동이 가능합니다. 단, 나이트는 체스판 밖으로는 이동할 수 없습니다. 체스판의 각 칸의 위치는 다음과 같이 표기합니다.예를 들어, A번줄과 1번줄이 겹치는 부분은 ‘A1’이라고 합니다. 나이트의 위치 pos가 매개변수로 주어질 때, 나이트를 한 번 움직여서 이동할 수 있는 칸은 몇개인지 return 하도록 solution 함수를 완성해주세요. 매개변수 설명나이트의 위치 pos가 solution 함수의 매개변수로 주어집니다. pos는 A부터 H까지의 대문자 알파벳 하나와 1 이상 8이하의 정수 하나로 이루어진 두 글자 문자열입니다. 잘못된 위치가 주어지는 경우는 없습니다. return 값 설명나이트를 한 번 움직여서 이동할 수 있는 칸의 개수를 return 해주세요. 예시 pos return “A7” 3 예시 설명나이트가 A7 위치에 있으면 아래 그림과 같이 왼쪽으로는 이동하지 못하고, 오른쪽으로는 맨 위를 제외한 나머지 세 칸으로 이동 가능합니다.따라서, 3을 return 하면 됩니다.","link":"/2020/09/21/1%EA%B8%89-1%EC%B0%A8-06%EB%B2%88/"},{"title":"Cos Pro Python 1급 1차 09번 문제풀이","text":"Contents of table: 문제내용 정답코드 Topic: 계단 게임 Review:잘못된 한 줄 코드를 찾아서 수정하는 형태의 문제. 이런 경우는 대입으로 잘못된 코드를 찾아내는 것이 가장 빠르다.A,B 가 비기는 케이스 ex) (0,0) 일 때, cnt -=1 이 되면은 안되므로 max(0, cnt-1) 로 고쳐준다. 정답코드 1234567891011121314151617def func(record): if record == 0: return 1 elif record == 1: return 2 return 0def solution(recordA, recordB): cnt = 0 for i in range(len(recordA)): if recordA[i] == recordB[i]: continue elif recordA[i] == func(recordB[i]): cnt += 3 else: cnt = max(0, cnt - 1) return cnt 문제내용#문제9두 학생 A와 B는 계단 게임을 하였습니다.계단 게임의 규칙은 아래와 같습니다. 계단 제일 아래에서 게임을 시작합니다. (0번째 칸) 가위바위보를 합니다. 이기면 계단 세 칸을 올라가고, 지면 한 칸을 내려가고, 비기면 제자리에 있습니다. 계단 제일 아래에서 지면 제자리에 있습니다. 2~4 과정을 열 번 반복합니다. A와 B가 계단 게임을 완료한 후에, A가 계단 위 몇 번째 칸에 있는지 파악하려고 합니다. A와 B가 낸 가위바위보 기록이 순서대로 들어있는 리스트 recordA와 recordB가 매개변수로 주어질 때, 게임을 마친 후의 A의 위치를 return 하도록 solution 함수를 작성했습니다. 그러나, 코드 일부분이 잘못되어있기 때문에, 몇몇 입력에 대해서는 올바르게 동작하지 않습니다. 주어진 코드에서 _한 줄_만 변경해서 모든 입력에 대해 올바르게 동작하도록 수정하세요. 매개변수 설명A와 B가 낸 가위바위보 기록이 순서대로 들어있는 리스트 recordA와 recordB가 매개변수로 주어집니다. recordA와 recordB의 원소는 0, 1, 2중 하나이고 순서대로 가위, 바위, 보를 의미합니다. recordA와 recordB의 길이는 10입니다. return 값 설명solution 함수는 계단 게임을 마친 후에 A가 계단 위 몇 번째 칸에 위치하는지를 return 합니다. 계단 제일 아래 칸은 0번째 칸입니다. 예시 recordA recordB return [2,0,0,0,0,0,1,1,0,0] [0,0,0,0,2,2,0,2,2,2] 14 예시 설명 recordA 보 가위 가위 가위 가위 가위 바위 바위 가위 가위 recordB 가위 가위 가위 가위 보 보 가위 보 보 보 result 0 0 0 0 +3 +6 +9 +8 +11 +14","link":"/2020/09/27/1%EA%B8%89-1%EC%B0%A8-09%EB%B2%88/"},{"title":"Card_Sales_EDA","text":"1234567# raw data load sales = pd.read_csv('C:\\Archaon\\projects\\Card_Sales\\Dataset\\copy_train.csv')necessary_cols= [ 'card_id', 'store_id', 'transacted_date', 'amount']unnecessary_cols = [ 'card_compay', 'transacted_time', 'installment_term','region','type_of_business' ]data1 = sales[necessary_cols] 1sales.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 6556613 entries, 0 to 6556612 Data columns (total 9 columns): # Column Dtype --- ------ ----- 0 store_id int16 1 card_id int32 2 card_company category 3 transacted_date category 4 transacted_time category 5 installment_term int8 6 region category 7 type_of_business category 8 amount float32 dtypes: category(5), float32(1), int16(1), int32(1), int8(1) memory usage: 125.2 MB 123# Before Downcasting sales_bd = np.round(sales.memory_usage().sum()/(1024*1024),1)sales_bd #450 123456789101112131415161718192021222324252627# Memory Downcast def downcast(df): cols = df.dtypes.index.tolist() types = df.dtypes.values.tolist() for i,t in enumerate(types): if 'int' in str(t): if df[cols[i]].min() &gt; np.iinfo(np.int8).min and df[cols[i]].max() &lt; np.iinfo(np.int8).max: df[cols[i]] = df[cols[i]].astype(np.int8) elif df[cols[i]].min() &gt; np.iinfo(np.int16).min and df[cols[i]].max() &lt; np.iinfo(np.int16).max: df[cols[i]] = df[cols[i]].astype(np.int16) elif df[cols[i]].min() &gt; np.iinfo(np.int32).min and df[cols[i]].max() &lt; np.iinfo(np.int32).max: df[cols[i]] = df[cols[i]].astype(np.int32) else: df[cols[i]] = df[cols[i]].astype(np.int64) elif 'float' in str(t): if df[cols[i]].min() &gt; np.finfo(np.float16).min and df[cols[i]].max() &lt; np.finfo(np.float16).max: df[cols[i]] = df[cols[i]].astype(np.float16) elif df[cols[i]].min() &gt; np.finfo(np.float32).min and df[cols[i]].max() &lt; np.finfo(np.float32).max: df[cols[i]] = df[cols[i]].astype(np.float32) else: df[cols[i]] = df[cols[i]].astype(np.float64) elif t == np.object: if cols[i] == 'date': df[cols[i]] = pd.to_datetime(df[cols[i]], format='%Y-%m-%d') else: df[cols[i]] = df[cols[i]].astype('category') return df 12# Downcast Datasales = downcast(sales) 12# After Downcasting sales_ad = np.round(sales.memory_usage().sum()/(1024*1024),1) #125.2 123456789101112131415# Downcasting Graph import plotly_express as pxdic = {'DataFrame':['sales'], 'Before downcasting':[sales_bd], 'After downcasting':[sales_ad]}memory = pd.DataFrame(dic)memory = pd.melt(memory, id_vars='DataFrame', var_name='Status', value_name='Memory (MB)')memory.sort_values('Memory (MB)',inplace=True)fig = px.bar(memory, x='DataFrame', y='Memory (MB)', color='Status', barmode='group', text='Memory (MB)')fig.update_traces(texttemplate='%{text} MB', textposition='outside')fig.update_layout(template='seaborn', title='Effect of Downcasting')fig.show() 1234567891011121314151617181920## EDA # 1. raw datasales.info()# RangeIndex: 6556613 entries, 0 to 6556612# Data columns (total 9 columns):# # Column Dtype# --- ------ -----# 0 store_id int16# 1 card_id int32# 2 card_company category# 3 transacted_date category# 4 transacted_time category# 5 installment_term int8# 6 region category# 7 type_of_business category# 8 amount float32# dtypes: category(5), float32(1), int16(1), int32(1), int8(1)# memory usage: 125.2 MB 12345678910111213# 1.1 missing values sales.isnull().sum()# store_id 0# card_id 0# card_company 0# transacted_date 0# transacted_time 0# installment_term 0# region 2042766# type_of_business 3952609# amount 0# dtype: int64 12345678910111213141516171819# 1.2 columnsimport seaborn as sns# 1.2.1 ['store_id']len(sales['store_id'].unique()) #1967## 1967개의 store_id 가 존재한다. store_counts = sales['store_id'].value_counts().reset_index()store_counts = pd.DataFrame(store_counts )store_counts.columns = ['store_id','counts']store_countsplt.figure(figsize=(12,8))ax = sns.barplot(x=&quot;store_id&quot; , y = &quot;counts&quot;, data =store_counts, order=store_counts['store_id'] )ax.set( ylabel=&quot;counts&quot;)# for item in ax.get_xticklabels():# item.set_rotation(90)plt.tight_layout()plt.show() 123456789# 1.2.2 ['card_company]len(sales) # = 6,556,613len(sales['card_id'].unique()) # = 3,950,001## sales 데이터의 entry 는 card_id를 기준으로 작성되었다.## 따라서, 1 entry = 1 card transaction 으로 이해할 수 있다. ## 하지만 데이터상의 고유 card_id 의 수는 3,950,001 개로, 전체 거래량인 6,556,613 에 비해서 40% 정도 작다. ## 그러므로 전체 거래량의 40%는 동일한 카드의 중복거래란 것을 확인할 수 있다. 12345678910111213141516# 1.2.3 ['card_company']sales.card_company ## Categories (8, object): [a, b, c, d, e, f, g, h]card_company = sales['card_company'].value_counts()card_company = pd.DataFrame(card_company)plt.figure(figsize=(12,8))ax = sns.barplot(x=card_company.index , y = &quot;card_company&quot;, data =card_company )ax.set( Xlabel=&quot;card company&quot;, ylabel=&quot;counts&quot;)plt.tight_layout()plt.show()## 카드사별로 전체 거래에서 사용된 빈도 차이가 있다. 하지만 거래의 집계는 card_id 가 아닌, store_id 별로## 진행을 할 예정이기 때문에 일단 참고만 하고 넘어가도록 한다. 1234567891011121314151617181920212223# 1.2.4 ['transacted_date']## 카드 거래일자는 2016년 6월1일부터, 2019년 2월 28일까지이며, day 기준으로 1002 일이다. ## 본 대회의 경우, 1002일 간의 카드거래 데이터로, 향후 3달후의 상점별 매출액을 예상하는 대회이다. ## 따라서 거래일자는 아래와 같은 구간으로 나눠진다. ## train period : 2016.6.1 ~ 2019.2.28 (1002 days) ## test period : 2019.3.1 ~ 2019.5.31 (91 days)sales['transacted_date']# 0 2016-06-01# 1 2016-06-01# 2 2016-06-01# 3 2016-06-01# 4 2016-06-02# ...# 6556608 2019-02-28# 6556609 2019-02-28# 6556610 2019-02-28# 6556611 2019-02-28# 6556612 2019-02-28#월별, 일별 2차 파생 그래프? 라고해야되나. 요거는 한 번 쭉 훑고 그다음에 다시 만들자.. ! ㅇㅋ~ 12345678910111213141516171819202122232425# 1.2.5 ['transacted_time'] &amp; ['installment_term]## transacted_time 과 installment_term 각각 카드거래 시각과 할부 개월수를 의미한다. ## 이러한 분포는 상점의 사업종류에 따라서 편차가 클 것으로 예상된다. ## 상점 하나(store_id == 1000)를 샘플로 골라서, 분포를 살펴보도록 하겠다. ## 선택된 상점의 경우에, type of business 가 '의복 소매업'이다. 따라서 사람들이 많이 쇼핑하는 ## 주말 오후 시간대 14 ~ 18 시 사이에, 카드결제 시간이 몰려 있는 것으로 확인된다. store_1000 = sales[ sales['store_id'] == 1000 ]###len(store_1000)blank = []for i in range(0,len(store_1000)): str1 = int(store_1000['transacted_time'].iloc[i][0:2]) blank.append(str1)blankblank = pd.DataFrame(blank, columns=['Count'])time_count = pd.DataFrame(blank['Count'].value_counts())###plt.figure(figsize=(12,8))ax = sns.barplot(x=time_count.index , y = &quot;Count&quot;, data =time_count )ax.set( Xlabel=&quot;transacted_time&quot;, ylabel=&quot;counts&quot;)plt.tight_layout()plt.show()","link":"/2020/10/08/Card_Sales_EDA/"},{"title":"Cos Pro Python 1급 1차 10번 문제풀이","text":"Contents of table: 문제내용 정답코드 Topic: 주식으로 최대 수익을 내세요 Review:Solution 함수를 역으로 훑어오면은, price=3 일때, mn 값이 1여야 하므로, 해당 아이디어를 가지고 수식을 훑으면수익률을 return 하는 부분인, mn - price가 아닌, price-mn 이 되어야 함을 알 수 있다. 정답코드 1234567891011def solution(prices): inf = 1000000001; mn = inf ans = -inf for price in prices: #price 1 , price2, mn = 1 , price3, mn = 1 if mn != inf: #mn =1001 , inf = 1001 // mn =1, inf = 1001 // mn=1, inf =1001 ans = max(ans, price - mn) # 문제 코드에서는 mn - price 로 되어있다. ans = max( -1001, 2-1)= 1 // ans = max(1, 3 - 1) = 2 mn = min(mn, price) #price 1, mn = 1 return ans 문제내용문제10지난 연속된 n일 동안의 주식 가격이 순서대로 들어있는 리스트가 있습니다. 이때, 다음 규칙에 따라 주식을 사고 팔았을 때의 최대 수익을 구하려 합니다. n일 동안 주식을 단 한 번 살 수 있습니다. n일 동안 주식을 단 한 번 팔 수 있습니다. 주식을 산 날에 바로 팔 수는 없으며, 최소 하루가 지나야 팔 수 있습니다. 적어도 한 번은 주식을 사야하며, 한 번은 팔아야 합니다. 주식을 팔 때는 반드시 이전에 주식을 샀어야 하며, 최대 수익은 양수가 아닐 수도 있습니다. 연속된 n 일 동안의 주식 가격이 순서대로 들어있는 리스트 prices가 매개변수로 주어질 때, 주식을 규칙에 맞게 한 번만 사고팔았을 때 얻을 수 있는 최대 수익을 return 하도록 solution 함수를 작성했습니다. 그러나, 코드 일부분이 잘못되어있기 때문에, 코드가 올바르게 동작하지 않습니다. 주어진 코드에서 _한 줄_만 변경해서 모든 입력에 대해 올바르게 동작하도록 수정해주세요. 매개변수 설명연속된 n 일 동안의 주식 가격이 순서대로 들어있는 리스트 prices가 solution 함수의 매개변수로 주어집니다. prices의 길이는 2 이상 1,000,000 이하입니다. prices의 각 원소는 1 이상 1,000 이하의 자연수입니다. #####return 값 설명주식을 규칙에 맞게 한 번만 사고팔았을 때 얻을 수 있는 최대 수익을 return 해주세요. 예시 prices return [1,2,3] 2 [3,1] -2 예시 설명예시 #1연속된 3일의 주가가 차례로 [1, 2, 3] 이며, 첫째 날에 주식을 사서 셋째 날에 팔면 수익은 2이고, 이때가 최대입니다. 예시 #2문제에서 설명한 것처럼 무조건 한 번은 매수하고, 한 번은 매도해야 합니다. 첫째 날에 매수하여 둘째 날에 매도하는 방법밖에 없기 때문에 수익은 -2, 즉 2만큼 손실을 보게 됩니다.","link":"/2020/09/27/1%EA%B8%89-1%EC%B0%A8-10%EB%B2%88/"},{"title":"Cos Pro Python 1급 2차 01번 문제풀이","text":"Contents of table: 문제내용 정답코드 Topic: 주식으로 최대 수익을 내세요 Review: 정답코드 1234567891011121314151617181920212223242526272829class ComicBook(): : cost = 500 day -= 2 if day &gt; 0: cost += return costclass Novel(): : cost = 1000 day -= 3 if day &gt; 0: cost += return costdef solution(book_types, day): books = [] for types in book_types: if types == &quot;comic&quot;: books.append(ComicBook()) elif types == &quot;novel&quot;: books.append(Novel()) total_price = 0 for book in books: total_price += book.get_rental_price(day) return total_price ### **문제내용** ### **문제10** 지난 연속된 n일 동안의 주식 가격이 순서대로 들어있는 리스트가 있습니다. 이때, 다음 규칙에 따라 주식을 사고 팔았을 때의 최대 수익을 구하려 합니다. * n일 동안 주식을 단 한 번 살 수 있습니다. * n일 동안 주식을 단 한 번 팔 수 있습니다. * 주식을 산 날에 바로 팔 수는 없으며, 최소 하루가 지나야 팔 수 있습니다. * 적어도 한 번은 주식을 사야하며, 한 번은 팔아야 합니다. 주식을 팔 때는 반드시 이전에 주식을 샀어야 하며, 최대 수익은 양수가 아닐 수도 있습니다. 연속된 n 일 동안의 주식 가격이 순서대로 들어있는 리스트 prices가 매개변수로 주어질 때, 주식을 규칙에 맞게 한 번만 사고팔았을 때 얻을 수 있는 최대 수익을 return 하도록 solution 함수를 작성했습니다. 그러나, 코드 일부분이 잘못되어있기 때문에, 코드가 올바르게 동작하지 않습니다. 주어진 코드에서 _**한 줄**_만 변경해서 모든 입력에 대해 올바르게 동작하도록 수정해주세요. --- ### **매개변수 설명** 연속된 n 일 동안의 주식 가격이 순서대로 들어있는 리스트 prices가 solution 함수의 매개변수로 주어집니다. * prices의 길이는 2 이상 1,000,000 이하입니다. * prices의 각 원소는 1 이상 1,000 이하의 자연수입니다. --- #####return 값 설명 주식을 규칙에 맞게 한 번만 사고팔았을 때 얻을 수 있는 최대 수익을 return 해주세요. --- ### **예시** | prices | return | |--------- |-------- | | [1,2,3] | 2 | | [3,1] | -2 | ### **예시 설명** 예시 #1 연속된 3일의 주가가 차례로 [1, 2, 3] 이며, 첫째 날에 주식을 사서 셋째 날에 팔면 수익은 2이고, 이때가 최대입니다. 예시 #2 문제에서 설명한 것처럼 무조건 한 번은 매수하고, 한 번은 매도해야 합니다. 첫째 날에 매수하여 둘째 날에 매도하는 방법밖에 없기 때문에 수익은 -2, 즉 2만큼 손실을 보게 됩니다.","link":"/2020/09/27/1%EA%B8%89-2%EC%B0%A8-01%EB%B2%88/"},{"title":"Kaggle M5 Competition Part 1 -EDA","text":"Contents of table: Kaggle M5 Competition Part 1 -EDA 1. Fetch the data 2. Downcasting 3. Exploratory Data Analysis 4. Melting the data Kaggle M5 Competition Part 1 -EDA 미국 Wal-Mart 에서 주최한 매출예측 대회이다. #ref:https://mofc.unic.ac.cy/m5-competition/https://www.kaggle.com/c/m5-forecasting-accuracy #아래 코드는 Kaggle Grandmaster Rob Mulla 의 모델링을 기반으로 재구성하였습니다. 대회설명:M5는 월마트에서 제공하는 계층적 판매 데이터를 사용하여, 향후 28 일 동안의 일일 판매를 예측하고 분포를 추정하는 것이 목표이다.데이터에는 가격, 프로모션, 요일 및 특별 이벤트와 같은 설명 변수가 포함된다. 데이터셋:calendar.csv - 제품 판매 날짜에 대한 정보를 포함.sales_train_validation.csv - 제품 및 매장 별 일일 판매량 기록 데이터 포함 [d_1-d_1913]sample_submission.csv - 제출 양식.sell_prices.csv - 상점 및 날짜별로 판매 된 제품의 가격에 대한 정보를 포함.sales_train_evaluation.cs - 제품 판매 포함 [d_1-d_1941] 12345678910111213import osimport pandas as pdimport numpy as npimport plotly_express as pximport plotly.graph_objects as gofrom plotly.subplots import make_subplotsimport matplotlib.pyplot as pltimport seaborn as snsimport gcimport warningswarnings.filterwarnings('ignore')from lightgbm import LGBMRegressorimport joblib 1. Fetch the data123456sales = pd.read_csv('C:\\\\Eric\\\\Projects\\\\Kaggle_M5\\Dataset\\\\sales_train_evaluation.csv')sales.name = 'sales'calendar = pd.read_csv('C:\\\\Eric\\\\Projects\\\\Kaggle_M5\\Dataset\\\\calendar.csv')calendar.name = 'calendar'prices = pd.read_csv('C:\\\\Eric\\\\Projects\\\\Kaggle_M5\\Dataset\\\\sell_prices.csv')prices.name = 'prices' 1sales.columns Index(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'd_1', 'd_2', 'd_3', 'd_4', ... 'd_1932', 'd_1933', 'd_1934', 'd_1935', 'd_1936', 'd_1937', 'd_1938', 'd_1939', 'd_1940', 'd_1941'], dtype='object', length=1947) 12345#빈 칸 처리되어있는 d 1942 ~ 1969 col들에 0 입력for d in range(1942,1970): col = 'd_' + str(d) sales[col] = 0 sales[col] = sales[col].astype(np.int16) 2. Downcasting1234#기본 데이터셋의 용량이 큰 만큼, 메모리 다운이 필요. sales_bd = np.round(sales.memory_usage().sum()/(1024*1024),1)calendar_bd = np.round(calendar.memory_usage().sum()/(1024*1024),1)prices_bd = np.round(prices.memory_usage().sum()/(1024*1024),1) 123456789101112131415161718192021222324252627#캐글의 memory downcasting 코드를 참고하여 아래와 같이 메모리 다운. def downcast(df): cols = df.dtypes.index.tolist() types = df.dtypes.values.tolist() for i,t in enumerate(types): if 'int' in str(t): if df[cols[i]].min() &gt; np.iinfo(np.int8).min and df[cols[i]].max() &lt; np.iinfo(np.int8).max: df[cols[i]] = df[cols[i]].astype(np.int8) elif df[cols[i]].min() &gt; np.iinfo(np.int16).min and df[cols[i]].max() &lt; np.iinfo(np.int16).max: df[cols[i]] = df[cols[i]].astype(np.int16) elif df[cols[i]].min() &gt; np.iinfo(np.int32).min and df[cols[i]].max() &lt; np.iinfo(np.int32).max: df[cols[i]] = df[cols[i]].astype(np.int32) else: df[cols[i]] = df[cols[i]].astype(np.int64) elif 'float' in str(t): if df[cols[i]].min() &gt; np.finfo(np.float16).min and df[cols[i]].max() &lt; np.finfo(np.float16).max: df[cols[i]] = df[cols[i]].astype(np.float16) elif df[cols[i]].min() &gt; np.finfo(np.float32).min and df[cols[i]].max() &lt; np.finfo(np.float32).max: df[cols[i]] = df[cols[i]].astype(np.float32) else: df[cols[i]] = df[cols[i]].astype(np.float64) elif t == np.object: if cols[i] == 'date': df[cols[i]] = pd.to_datetime(df[cols[i]], format='%Y-%m-%d') else: df[cols[i]] = df[cols[i]].astype('category') return df 123sales = downcast(sales)prices = downcast(prices)calendar = downcast(calendar) 1234#메모리 다운 후의 메모리 사용량 체크. sales_ad = np.round(sales.memory_usage().sum()/(1024*1024),1)calendar_ad = np.round(calendar.memory_usage().sum()/(1024*1024),1)prices_ad = np.round(prices.memory_usage().sum()/(1024*1024),1) 123456789101112#다운 캐스팅이 DataFrame의 메모리 사용량에 얼마나 많은 영향을 미쳤는지 시각화.1/4 미만으로 줄일 수 있음. dic = {'DataFrame':['sales','calendar','prices'], 'Before downcasting':[sales_bd,calendar_bd,prices_bd], 'After downcasting':[sales_ad,calendar_ad,prices_ad]}memory = pd.DataFrame(dic)memory = pd.melt(memory, id_vars='DataFrame', var_name='Status', value_name='Memory (MB)')memory.sort_values('Memory (MB)',inplace=True)fig = px.bar(memory, x='DataFrame', y='Memory (MB)', color='Status', barmode='group', text='Memory (MB)')fig.update_traces(texttemplate='%{text} MB', textposition='outside')fig.update_layout(template='seaborn', title='Effect of Downcasting')fig.show() 3. Exploratory Data Analysis123456walmart 에서 제공하는 세일즈 데이터는, wrt, 즉 with respect to [ cols ]State: CA, WI, TX (3)Store: CA_1, CA_2, TX_1, WI_1, ... (10)Category: FOOD, HOBBIES, HOUSEHOLD (3) Department:FOOD_1,2,3 , HOBBIES_1,2, ... (7)item_id:: each unique id # (3,049) 1234567891011#plotly_express 에서 제공하는 treemap 을 활용해서, 각 제품 id 를 count var로 잡고, data col 들의 관계를 directory 형태로 시각화.group = sales.groupby(['state_id','store_id','cat_id','dept_id'],as_index=False)['item_id'].count().dropna()group['USA'] = 'United States of America'group.rename(columns={'state_id':'State','store_id':'Store','cat_id':'Category','dept_id':'Department','item_id':'Count'},inplace=True)fig = px.treemap(group, path=['USA', 'State', 'Store', 'Category', 'Department'], values='Count', color='Count', color_continuous_scale= px.colors.sequential.Sunset, title='Walmart: Distribution of items')fig.update_layout(template='seaborn')fig.show() 4. Melting the data#4.1 Convert from wide to long format 1머신러닝 포맷에 적합시키기 위해서는 와이드 형식의 판매 데이터 프레임을 긴 형식으로 변환이 필요하다. sales 데이터셋의 row 는 30490(== # of items), 데이터셋을 melt하게되면은 sales, calendar 30490 x 1969 = 60034810 개의 row 를 가지게 된다. 1df = pd.melt(sales, id_vars=['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'], var_name='d', value_name='sold').dropna() 12df = pd.merge(df, calendar, on='d', how='left')df = pd.merge(df, prices, on=['store_id','item_id','wm_yr_wk'], how='left') 1234567#Store 별로 매출액합계를 violin plot 을 활용해서 시각화. group = df.groupby(['year','date','state_id','store_id'], as_index=False)['sold'].sum().dropna()fig = px.violin(group, x='store_id', color='state_id', y='sold',box=True)fig.update_xaxes(title_text='Store')fig.update_yaxes(title_text='Total items sold')fig.update_layout(template='seaborn',title='Distribution of Items sold wrt Stores',legend_title_text='State')fig.show()","link":"/2020/09/22/project_kaggle_m5_0922/"},{"title":"Kaggle M5 Competition Part 2 -Modeling","text":"Contents of table: Kaggle M5 Competition Part 2 -Modeling 5. Feature Engineering 6. Modeling and Prediction Kaggle M5 Competition Part 2 -Modeling 5. Feature Engineering1#5.1 Label Encoding 1234567#id, department, category, store, state 를 코드값으로 저장 d_id = dict(zip(df.id.cat.codes, df.id))d_item_id = dict(zip(df.item_id.cat.codes, df.item_id))d_dept_id = dict(zip(df.dept_id.cat.codes, df.dept_id))d_cat_id = dict(zip(df.cat_id.cat.codes, df.cat_id))d_store_id = dict(zip(df.store_id.cat.codes, df.store_id))d_state_id = dict(zip(df.state_id.cat.codes, df.state_id)) 12345678910111213#1gc.collect()#2df.d = df['d'].apply(lambda x: x.split('_')[1]).astype(np.int16)cols = df.dtypes.index.tolist()types = df.dtypes.values.tolist()for i,type in enumerate(types): if type.name == 'category': df[cols[i]] = df[cols[i]].cat.codes #3df.drop('date',axis=1,inplace=True) 1import time 1#5.2 introduce lags 1234#lag col들을 추가lags = [1,2,3,6,12,24,36]for lag in lags: df['sold_lag_'+str(lag)] = df.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],as_index=False)['sold'].shift(lag).astype(np.float16) 1#5.3 Mean Encoding 1234567891011121314%time#판매량 평균을 wrt item, state, store, category, department 별로 col 생성 df['iteam_sold_avg'] = df.groupby('item_id')['sold'].transform('mean').astype(np.float16)df['state_sold_avg'] = df.groupby('state_id')['sold'].transform('mean').astype(np.float16)df['store_sold_avg'] = df.groupby('store_id')['sold'].transform('mean').astype(np.float16)df['cat_sold_avg'] = df.groupby('cat_id')['sold'].transform('mean').astype(np.float16)df['dept_sold_avg'] = df.groupby('dept_id')['sold'].transform('mean').astype(np.float16)df['cat_dept_sold_avg'] = df.groupby(['cat_id','dept_id'])['sold'].transform('mean').astype(np.float16)df['store_item_sold_avg'] = df.groupby(['store_id','item_id'])['sold'].transform('mean').astype(np.float16)df['cat_item_sold_avg'] = df.groupby(['cat_id','item_id'])['sold'].transform('mean').astype(np.float16)df['dept_item_sold_avg'] = df.groupby(['dept_id','item_id'])['sold'].transform('mean').astype(np.float16)df['state_store_sold_avg'] = df.groupby(['state_id','store_id'])['sold'].transform('mean').astype(np.float16)df['state_store_cat_sold_avg'] = df.groupby(['state_id','store_id','cat_id'])['sold'].transform('mean').astype(np.float16)df['store_cat_dept_sold_avg'] = df.groupby(['store_id','cat_id','dept_id'])['sold'].transform('mean').astype(np.float16) Wall time: 1 ms 1#5.4 Rolling Window Statistics 1df['rolling_sold_mean'] = df.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'])['sold'].transform(lambda x: x.rolling(window=7).mean()).astype(np.float16) 1#5.5 Expanding Window Statistics 1df['expanding_sold_mean'] = df.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'])['sold'].transform(lambda x: x.expanding(2).mean()).astype(np.float16) 1#5.6 Trends 12345#Selling Trend는 간단하게, 평균보다 큰지 작은지 만을 비교. df['daily_avg_sold'] = df.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id','d'])['sold'].transform('mean').astype(np.float16)df['avg_sold'] = df.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'])['sold'].transform('mean').astype(np.float16)df['selling_trend'] = (df['daily_avg_sold'] - df['avg_sold']).astype(np.float16)df.drop(['daily_avg_sold','avg_sold'],axis=1,inplace=True) 1#5.7 Save the data 12#lag 추가로 인해서, d 35까지 빈 row 들이 많이 발생했으므로 해당기간을 제외. df = df[df['d']&gt;=36] 1df.info() &lt;class 'pandas.core.frame.DataFrame'&gt; Int64Index: 58967660 entries, 1067150 to 60034809 Data columns (total 43 columns): id int16 item_id int16 dept_id int8 cat_id int8 store_id int8 state_id int8 d int16 sold int16 wm_yr_wk int16 weekday int8 wday int8 month int8 year int16 event_name_1 int8 event_type_1 int8 event_name_2 int8 event_type_2 int8 snap_CA int8 snap_TX int8 snap_WI int8 sell_price float16 sold_lag_1 float16 sold_lag_2 float16 sold_lag_3 float16 sold_lag_6 float16 sold_lag_12 float16 sold_lag_24 float16 sold_lag_36 float16 iteam_sold_avg float16 state_sold_avg float16 store_sold_avg float16 cat_sold_avg float16 dept_sold_avg float16 cat_dept_sold_avg float16 store_item_sold_avg float16 cat_item_sold_avg float16 dept_item_sold_avg float16 state_store_sold_avg float16 state_store_cat_sold_avg float16 store_cat_dept_sold_avg float16 rolling_sold_mean float16 expanding_sold_mean float16 selling_trend float16 dtypes: float16(23), int16(6), int8(14) memory usage: 4.4 GB 123df.to_pickle('data.pkl')del dfgc.collect() 6. Modeling and Prediction1import time 123456%time data = pd.read_pickle('data.pkl') # FE후에 pickle 형태로 저장시켰던 데이터를 로드. valid = data[(data['d']&gt;=1914) &amp; (data['d']&lt;1942)][['id','d','sold']] # 1914 ~ 1942 validation periodtest = data[data['d']&gt;=1942][['id','d','sold']] # d &gt;= 1942 test and eval period eval_preds = test['sold'] # eval = testvalid_preds = valid['sold'] # val = val Wall time: 0 ns 12345678910111213141516171819202122232425262728293031#Get the store idsstores = sales.store_id.cat.codes.unique().tolist()for store in stores: #store 별로 나눠서 prediction 진행 df = data[data['store_id']==store] #Split the data X_train, y_train = df[df['d']&lt;1914].drop('sold',axis=1), df[df['d']&lt;1914]['sold'] X_valid, y_valid = df[(df['d']&gt;=1914) &amp; (df['d']&lt;1942)].drop('sold',axis=1), df[(df['d']&gt;=1914) &amp; (df['d']&lt;1942)]['sold'] X_test = df[df['d']&gt;=1942].drop('sold',axis=1) #Train and validate model = LGBMRegressor( n_estimators=1000, learning_rate=0.3, subsample=0.8, colsample_bytree=0.8, max_depth=8, num_leaves=50, min_child_weight=300 ) print('*****Prediction for Store: {}*****'.format(d_store_id[store])) model.fit(X_train, y_train, eval_set=[(X_train,y_train),(X_valid,y_valid)], eval_metric='rmse', verbose=20, early_stopping_rounds=20) valid_preds[X_valid.index] = model.predict(X_valid) eval_preds[X_test.index] = model.predict(X_test) filename = 'model'+str(d_store_id[store])+'.pkl' # save model joblib.dump(model, filename) del model, X_train, y_train, X_valid, y_valid gc.collect() *****Prediction for Store: CA_1***** Training until validation scores don't improve for 20 rounds [20] training's rmse: 0.843923 training's l2: 0.712206 valid_1's rmse: 0.556612 valid_1's l2: 0.309817 [40] training's rmse: 0.805702 training's l2: 0.649156 valid_1's rmse: 0.536648 valid_1's l2: 0.287992 [60] training's rmse: 0.782521 training's l2: 0.612339 valid_1's rmse: 0.529075 valid_1's l2: 0.27992 [80] training's rmse: 0.765509 training's l2: 0.586004 valid_1's rmse: 0.519001 valid_1's l2: 0.269362 [100] training's rmse: 0.746824 training's l2: 0.557746 valid_1's rmse: 0.516391 valid_1's l2: 0.26666 [120] training's rmse: 0.736669 training's l2: 0.542682 valid_1's rmse: 0.512239 valid_1's l2: 0.262389 [140] training's rmse: 0.725183 training's l2: 0.52589 valid_1's rmse: 0.507517 valid_1's l2: 0.257574 [160] training's rmse: 0.71879 training's l2: 0.516659 valid_1's rmse: 0.503054 valid_1's l2: 0.253063 [180] training's rmse: 0.713246 training's l2: 0.508719 valid_1's rmse: 0.501668 valid_1's l2: 0.25167 Early stopping, best iteration is: [177] training's rmse: 0.713815 training's l2: 0.509531 valid_1's rmse: 0.501194 valid_1's l2: 0.251195 *****Prediction for Store: CA_2***** Training until validation scores don't improve for 20 rounds [20] training's rmse: 0.509193 training's l2: 0.259277 valid_1's rmse: 0.488679 valid_1's l2: 0.238808 [40] training's rmse: 0.476985 training's l2: 0.227515 valid_1's rmse: 0.481392 valid_1's l2: 0.231738 [60] training's rmse: 0.459124 training's l2: 0.210795 valid_1's rmse: 0.469844 valid_1's l2: 0.220753 [80] training's rmse: 0.446454 training's l2: 0.199321 valid_1's rmse: 0.466131 valid_1's l2: 0.217278 [100] training's rmse: 0.44062 training's l2: 0.194146 valid_1's rmse: 0.465138 valid_1's l2: 0.216353 [120] training's rmse: 0.435579 training's l2: 0.189729 valid_1's rmse: 0.462275 valid_1's l2: 0.213698 [140] training's rmse: 0.433312 training's l2: 0.187759 valid_1's rmse: 0.46174 valid_1's l2: 0.213204 [160] training's rmse: 0.430487 training's l2: 0.185319 valid_1's rmse: 0.461825 valid_1's l2: 0.213283 Early stopping, best iteration is: [149] training's rmse: 0.431706 training's l2: 0.18637 valid_1's rmse: 0.461223 valid_1's l2: 0.212727 *****Prediction for Store: CA_3***** Training until validation scores don't improve for 20 rounds [20] training's rmse: 1.31768 training's l2: 1.73629 valid_1's rmse: 0.620532 valid_1's l2: 0.38506 [40] training's rmse: 1.25016 training's l2: 1.56289 valid_1's rmse: 0.599518 valid_1's l2: 0.359422 [60] training's rmse: 1.21357 training's l2: 1.47275 valid_1's rmse: 0.583401 valid_1's l2: 0.340357 [80] training's rmse: 1.18962 training's l2: 1.41519 valid_1's rmse: 0.580415 valid_1's l2: 0.336882 [100] training's rmse: 1.16704 training's l2: 1.36198 valid_1's rmse: 0.573824 valid_1's l2: 0.329274 Early stopping, best iteration is: [83] training's rmse: 1.18341 training's l2: 1.40046 valid_1's rmse: 0.571149 valid_1's l2: 0.326211 *****Prediction for Store: CA_4***** Training until validation scores don't improve for 20 rounds [20] training's rmse: 0.379545 training's l2: 0.144055 valid_1's rmse: 0.306421 valid_1's l2: 0.0938936 [40] training's rmse: 0.362723 training's l2: 0.131568 valid_1's rmse: 0.296737 valid_1's l2: 0.0880528 [60] training's rmse: 0.352526 training's l2: 0.124275 valid_1's rmse: 0.286469 valid_1's l2: 0.0820644 [80] training's rmse: 0.347152 training's l2: 0.120515 valid_1's rmse: 0.283419 valid_1's l2: 0.0803261 [100] training's rmse: 0.342128 training's l2: 0.117052 valid_1's rmse: 0.279012 valid_1's l2: 0.0778477 [120] training's rmse: 0.339248 training's l2: 0.115089 valid_1's rmse: 0.27756 valid_1's l2: 0.0770398 [140] training's rmse: 0.336076 training's l2: 0.112947 valid_1's rmse: 0.27745 valid_1's l2: 0.0769786 Early stopping, best iteration is: [129] training's rmse: 0.337326 training's l2: 0.113789 valid_1's rmse: 0.276789 valid_1's l2: 0.0766123 *****Prediction for Store: TX_1***** Training until validation scores don't improve for 20 rounds [20] training's rmse: 0.779231 training's l2: 0.607202 valid_1's rmse: 0.495078 valid_1's l2: 0.245102 [40] training's rmse: 0.734945 training's l2: 0.540143 valid_1's rmse: 0.477927 valid_1's l2: 0.228414 [60] training's rmse: 0.715 training's l2: 0.511225 valid_1's rmse: 0.474993 valid_1's l2: 0.225618 [80] training's rmse: 0.700945 training's l2: 0.491324 valid_1's rmse: 0.471686 valid_1's l2: 0.222487 [100] training's rmse: 0.688138 training's l2: 0.473534 valid_1's rmse: 0.469721 valid_1's l2: 0.220638 [120] training's rmse: 0.671506 training's l2: 0.45092 valid_1's rmse: 0.468799 valid_1's l2: 0.219772 Early stopping, best iteration is: [111] training's rmse: 0.678168 training's l2: 0.459912 valid_1's rmse: 0.466017 valid_1's l2: 0.217172 *****Prediction for Store: TX_2***** Training until validation scores don't improve for 20 rounds [20] training's rmse: 0.949797 training's l2: 0.902115 valid_1's rmse: 0.519843 valid_1's l2: 0.270237 [40] training's rmse: 0.901254 training's l2: 0.812259 valid_1's rmse: 0.50753 valid_1's l2: 0.257587 [60] training's rmse: 0.860935 training's l2: 0.741208 valid_1's rmse: 0.496691 valid_1's l2: 0.246702 [80] training's rmse: 0.837279 training's l2: 0.701036 valid_1's rmse: 0.500869 valid_1's l2: 0.25087 Early stopping, best iteration is: [60] training's rmse: 0.860935 training's l2: 0.741208 valid_1's rmse: 0.496691 valid_1's l2: 0.246702 *****Prediction for Store: TX_3***** Training until validation scores don't improve for 20 rounds [20] training's rmse: 0.741642 training's l2: 0.550033 valid_1's rmse: 0.569192 valid_1's l2: 0.323979 [40] training's rmse: 0.71047 training's l2: 0.504767 valid_1's rmse: 0.557032 valid_1's l2: 0.310284 [60] training's rmse: 0.68682 training's l2: 0.471721 valid_1's rmse: 0.546532 valid_1's l2: 0.298697 [80] training's rmse: 0.672727 training's l2: 0.452562 valid_1's rmse: 0.541006 valid_1's l2: 0.292688 [100] training's rmse: 0.66163 training's l2: 0.437754 valid_1's rmse: 0.539347 valid_1's l2: 0.290895 [120] training's rmse: 0.650395 training's l2: 0.423014 valid_1's rmse: 0.534985 valid_1's l2: 0.286208 [140] training's rmse: 0.645165 training's l2: 0.416238 valid_1's rmse: 0.532259 valid_1's l2: 0.2833 Early stopping, best iteration is: [132] training's rmse: 0.646645 training's l2: 0.418149 valid_1's rmse: 0.531403 valid_1's l2: 0.28239 *****Prediction for Store: WI_1***** Training until validation scores don't improve for 20 rounds [20] training's rmse: 0.40387 training's l2: 0.163111 valid_1's rmse: 0.351971 valid_1's l2: 0.123884 [40] training's rmse: 0.379547 training's l2: 0.144056 valid_1's rmse: 0.339714 valid_1's l2: 0.115405 [60] training's rmse: 0.370228 training's l2: 0.137069 valid_1's rmse: 0.338534 valid_1's l2: 0.114605 [80] training's rmse: 0.362681 training's l2: 0.131537 valid_1's rmse: 0.335793 valid_1's l2: 0.112757 Early stopping, best iteration is: [75] training's rmse: 0.363574 training's l2: 0.132186 valid_1's rmse: 0.335287 valid_1's l2: 0.112418 *****Prediction for Store: WI_2***** Training until validation scores don't improve for 20 rounds [20] training's rmse: 0.798844 training's l2: 0.638151 valid_1's rmse: 0.99757 valid_1's l2: 0.995147 [40] training's rmse: 0.75986 training's l2: 0.577388 valid_1's rmse: 0.979328 valid_1's l2: 0.959084 [60] training's rmse: 0.729671 training's l2: 0.53242 valid_1's rmse: 0.968394 valid_1's l2: 0.937787 Early stopping, best iteration is: [57] training's rmse: 0.732588 training's l2: 0.536685 valid_1's rmse: 0.967836 valid_1's l2: 0.936707 *****Prediction for Store: WI_3***** Training until validation scores don't improve for 20 rounds [20] training's rmse: 0.803068 training's l2: 0.644919 valid_1's rmse: 0.580289 valid_1's l2: 0.336735 [40] training's rmse: 0.762335 training's l2: 0.581154 valid_1's rmse: 0.573159 valid_1's l2: 0.328512 [60] training's rmse: 0.739142 training's l2: 0.546331 valid_1's rmse: 0.566164 valid_1's l2: 0.320541 Early stopping, best iteration is: [51] training's rmse: 0.748455 training's l2: 0.560184 valid_1's rmse: 0.563976 valid_1's l2: 0.318069 123456789101112131415161718192021222324actual = Falseif actual == False: #대회 종료 1달 전에, validation data 를 추가로 제공하기 때문에, 그 전에 training data 로만 생성한 valid 를 쓸지, 아니면 추가 제공 valid 를 쓸지 결정 validation = sales[['id']+['d_' + str(i) for i in range(1914,1942)]] validation['id']=pd.read_csv('C:\\\\Eric\\\\Projects\\\\Kaggle_M5\\Dataset\\\\sales_train_validation.csv').id validation.columns=['id'] + ['F' + str(i + 1) for i in range(28)]else: valid['sold'] = valid_preds validation = valid[['id','d','sold']] validation = pd.pivot(validation, index='id', columns='d', values='sold').reset_index() validation.columns=['id'] + ['F' + str(i + 1) for i in range(28)] validation.id = validation.id.map(d_id).str.replace('evaluation','validation')#predictio data 생성 test['sold'] = eval_predsevaluation = test[['id','d','sold']]evaluation = pd.pivot(evaluation, index='id', columns='d', values='sold').reset_index()evaluation.columns=['id'] + ['F' + str(i + 1) for i in range(28)]evaluation.id = evaluation.id.map(d_id)#Submission 파일 생성 submit = pd.concat([validation,evaluation]).reset_index(drop=True)submit.to_csv('M5_submission.csv',index=False) 1","link":"/2020/09/21/project_kaggle_m5_0922%20Modeling/"}],"tags":[{"name":"Python","slug":"Python","link":"/tags/Python/"}],"categories":[{"name":"Python","slug":"Python","link":"/categories/Python/"},{"name":"Cos Pro 1급","slug":"Python/Cos-Pro-1급","link":"/categories/Python/Cos-Pro-1%EA%B8%89/"},{"name":"Portfolio","slug":"Portfolio","link":"/categories/Portfolio/"},{"name":"Kaggle","slug":"Kaggle","link":"/categories/Kaggle/"}]}